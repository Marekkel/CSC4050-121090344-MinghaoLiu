[
    {
        "id": 50,
        "query": "===================================================\nkombu-sqlalchemy - Kombu transport using SQLAlchemy\n===================================================\n\n:version: 1.1.0\n\nDeprecated\n==========\n\nkombu-sqlalchemy has now moved into Kombu core, so this repository\nis no longer in use.\n\nTo upgrade, install the latest Kombu version.\n\n**ORIGINAL README BELOW**\n\n\nIntroduction\n============\n\nThis package enables you to use SQLAlchemy as the message store\nfor `Kombu`_.\n\n\n``kombu-sqlalchemy`` contains a single transport,\n``sqlakombu.transport.Transport``, which is used like this::\n\n    >>> from kombu.connection import BrokerConnection\n    >>> c = BrokerConnection(DB_URL, transport=\"sqlakombu.transport.Transport\")\n\n``DB_URL`` should be a valid SQLAlchemy database connection url in the form::\n\n    \"dialect+driver://username:password@host:port/database\"\n\n\n.. _`Kombu`: http://pypi.python.org/pypi/kombu\n\nInstallation\n============\n\nYou can install ``kombu-sqlalchemy`` either via the Python Package Index (PyPI)\nor from source.\n\nTo install using ``pip``,::\n\n    $ pip install kombu-sqlalchemy\n\n\nTo install using ``easy_install``,::\n\n    $ easy_install kombu-sqlalchemy\n\n\nIf you have downloaded a source tarball you can install it\nby doing the following,::\n\n    $ python setup.py build\n    # python setup.py install # as root\n\nLicense\n=======\n\nThis software is licensed under the ``New BSD License``. See the ``LICENSE``\nfile in the top distribution directory for the full license text.\n\n.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 51,
        "query": ".. _docutils: http://docutils.sourceforge.net/\n.. _Django: https://www.djangoproject.com/\n.. _django-materialize-css: https://pypi.python.org/pypi/django-materialize-css/\n.. _django-crispy-forms: https://github.com/maraujop/django-crispy-forms\n.. _Materialize: http://materializecss.com \n\nThis repo is Deprecated\n=======================\nPlease dont use me, i no longer have maintenance.\n\nLooking for someone to maintain the project\n===========================================\nIf you are interested in continuing with the project and maintaining it, please send me an email.\n\nIntroduction\n============\n\nThis is a `Django`_ application to add `django-crispy-forms`_ layout objects for `Materialize`_.\n\nThis app does not embed a `Materialize`_ release, you will have to install `django-materialize-css`_ as a dependency or download/ link to latests updates of materializecss in your project.\n\nLinks\n*****\n\n* Read the documentation on `Read the docs soon!`;\n* Download and install this from `PyPi package <https://pypi.python.org/pypi/crispy-forms-materialize/>`__\n* Clone it on this `Github repository <https://github.com/edvm/crispy-forms-materialize>`__\n\nRequires\n========\n\n* `django-crispy-forms`_ above 1.4.x version\n* `django-materialize-css`_ above 1.4.x version (optional)\n\nYou can get django-materialize-css from `PyPI <https://pypi.python.org/pypi/django-materialize-css/>`__ and `github <https://github.com/edvm/django-materialize-css>`__\n\nInstallation\n============\n\nProbably the best way to install is by using `PIP`::\n\n    $ pip install crispy-forms-materialize\n\nIf you want to stay on the bleeding edge of the app::\n\n    $ git clone https://github.com/edvm/crispy-forms-materialize.git\n    $ cd crispy-forms-materialize\n    $ python setup.py install\n\n\nThen add the app in your project's ``INSTALLED_APPS`` like this :\n\n.. sourcecode:: python\n\n    INSTALLED_APPS = (\n        ...\n        'materialize',\n        'crispy_forms',\n        'crispy_forms_materialize',\n        ...\n    )\n\nThen change crispy template pack settings to start using it in your forms:\n\n.. sourcecode:: python\n\n    # Default layout to use with \"crispy_forms\"\n    CRISPY_TEMPLATE_PACK = 'materialize_css_forms'\n\nAll other `django-crispy-forms`_ settings option apply, see its documentation for more details.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 52,
        "query": "*WARNING*: This project is currently UNMAINTAINED. Please use the official one: https://github.com/mailjet/mailjet-apiv3-python\n\n==============\nDjango-Mailjet\n==============\nUn-official Django email backend for use with Mailjet - https://www.mailjet.com/\n\nOverview\n========\nDjango-Mailjet is a drop-in mail backend for Django.\n\nGetting going\n=============\nInstall django-mailjet:\n    ``python3 -m pip install django-mailjet``\nAdd the following to your ``settings.py``::\n\n    EMAIL_BACKEND = 'django_mailjet.backends.MailjetBackend'\n    MAILJET_API_KEY = 'API-KEY'\n    MAILJET_API_SECRET = 'API-SECRET'\n\nReplace ``API-KEY`` and ``API-SECRET`` with the values from your Mailjet account details.\n\nNow, when you use ``django.core.mail.send_mail``, Mailjet will send the messages.\n\n.. _Mailjet: http://mailjet.com\n\n*NOTE*: Django-Mailjet does **NOT**\nvalidate your data for compliance with Mailjet's API.\nYou must ensure what you send is appropriate.\n\n\nDjango Email Backend Reference\n================================\n* https://docs.djangoproject.com/en/dev/topics/email/#email-backends\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 53,
        "query": "------------------\nNOTICE: Deprecated\n------------------\n\nThis project is deprecated and no longer actively maintained by `Disqus <https://disqus.com/>`_. However there is a fork being maintained by YPlan at `github.com/YPlan/django-modeldict <https://github.com/YPlan/django-modeldict>`_ and a similar project by Disqus at `github.com/disqus/durabledict <https://github.com/disqus/durabledict/>`_.\n\n----------------\ndjango-modeldict\n----------------\n\nModelDict is a very efficient way to store things like settings in your database. The entire model is transformed into a dictionary (lazily) as well as stored in your cache. It's invalidated only when it needs to be (both in process and based on ``CACHE_BACKEND``).\n\nQuick example usage. More docs to come (maybe?)::\n\n\n\tclass Setting(models.Model):\n\t    key = models.CharField(max_length=32)\n\t    value = models.CharField(max_length=200)\n\tsettings = ModelDict(Setting, key='key', value='value', instances=False)\n\t\n\t# access missing value\n\tsettings['foo']\n\t>>> KeyError\n\t\n\t# set the value\n\tsettings['foo'] = 'hello'\n\t\n\t# fetch the current value using either method\n\tSetting.objects.get(key='foo').value\n\t>>> 'hello'\n\t\n\tsettings['foo']\n\t>>> 'hello'\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 54,
        "query": "CAUTION: this project is not maintained anymore as it's maintainer don't use it anymore\n(and switched to tmux). If you contribute a bit, you may reclaim this project.\n\n\nscreenutils\n===========\n\nscreenutils is a set of classes that should help handling gnu-screen windows.\n\nIt requires gnu-screen binary installed (named screen and in your path) to work.\n\nFeel free to report any modification you made, the whole code source is\navailable under the terms of the GPLv2 but I think about using a more permissave license (WTFPL).\n\nExample usage\n-------------\n\nExample in a python console::\n\n   >>> from screenutils import list_screens, Screen\n   >>> list_screens()\n   []\n   >>> s = Screen(\"session1\",True)\n   >>> # funky prompts could reduce log visibility. Use sh or bash for best results\n   >>> s.send_commands('bash')\n   >>> s.enable_logs()\n   >>> s.send_commands(\"df\")\n   >>> print next(s.logs)\n   df\n   Filesystem           1K-blocks      Used Available Use% Mounted on\n   /dev/sda6             20161172   8084052  11052980  43% /\n   none                   1505916       304   1505612   1% /dev\n   none                   1512676       936   1511740   1% /dev/shm\n   none                   1512676       380   1512296   1% /var/run\n   none                   1512676         0   1512676   0% /var/lock\n   none                   1512676         0   1512676   0% /lib/init/rw\n   none                  20161172   8084052  11052980  43% /var/lib/ureadahead/debugfs\n   /dev/sda7            403567768 196284216 186783420  52% /home\n   popi@popi-laptop:~/Dev/github/screenutils$\n   >>> s.disable_logs()\n   >>> s = None\n   >>> s = Screen(\"session1\")\n   >>> s.exists\n   True\n   >>> s2 = Screen(\"session2\")\n   >>> s2.exists\n   False\n   >>> s2.initialize()\n   >>> s2.exists\n   True\n   >>> list_screens()\n   [<Screen 'session2'>, <Screen 'session1'>]\n   >>>\n\n\nInstallation\n-------------\n\nYou could install screenutils from github, by doing the following::\n\n    $ pip install git+http://github.com/Christophe31/screenutils.git\n\nOr by just using the packages published on Pypi, for instance with pip::\n\n    $ pip install screenutils\n\nFeatures\n---------\n\n* screens listing\n* screen session creation\n* screen session closing\n* screen code insertion\n* screen monitoring/logging\n* screen session sharing with unix users (see below)\n\nCore Documentation\n------------------\n\n**Screen class**:\n\n* ``Screen(name, initialize=False)`` Create a new screen.\n\n  - ``name`` (required): The name associated with the screen.\n\n  - ``initialize``: If True, creates a screen session if it does not exists.\n\n* ``screen.id`` (property) the id of the screen as a string.\n* ``screen.status`` (property) the status of the screen as a string.\n* ``screen.exists`` (property) True if the screen exists (has been initialized)\n\n  - NOTE: ``.id``, ``.status``, ``.exists`` are all based off of the output of ``screen -ls``\n\n* ``screen.initialize`` Initialize a screen if does not exists yet. Equivalent to running ``screen -UR screen_name``\n* ``screen.enable_logs()`` turns Screen's logging on. The Logfile's name is automatically set to that of the ``Screen`` object.\n* ``screen.logs`` A generator that acts like ``tailF`` on the logfile.\n* ``screen.disable_logs()`` turns logging off.\n* ``screen.kill()`` Quit the screen. Equivalent to running ``screen -x screen_name -X quit``\n* ``screen.detach()`` Detach from the screen.\n* ``screen.send_commands(*commands)`` send bash commands to the screen.\n\n  - ``*commands`` the command(s) to run (as a string).\n\n* ``screen.add_user_access(unix_user_name)`` Allow another user to access the screen.\n\n  - ``unix_user_name`` (required): the unix name of the user to add.\n\n  - \\*NOTE: to allow this feature, you will **need** to change some unix rights:\n\n    + ``sudo chmod +s /usr/bin/screen``\n\n    + ``sudo chmod 755 /var/run/screen``\n\n**Functions** :\n\n* ``list_screens()`` list screens. Returns a list of ``Screen`` instances.\n\n**Exceptions** :\n\n* ``ScreenNotFoundError``: Raised when a screen wasn't found.\n\nKnown issues\n-------------\n\nThis may not work properly with bpython.\n\nRoadmap\n--------\n\n* multi windows screen support\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 55,
        "query": "**UNMAINTAINED**\n\n***READ THE COMPLETE FILE BEFORE INSTALLATION. AT LEAST READ THE *CAUTION* SECTION THOROUGHLY***\n\n# Installation:\n***INSTALLATION SHOULD HAPPEN LOCALLY FOR THE USER. DO NOT PROVIDE ROOT/ADMINISTRATIVE PRIVILEGES (OTHER THAN PYTHON INSTALLATION)***\n\n## Windows 10\n### Recommended:\nUse `pip` method as described below.\n\n### Else, if you really insist on a Windows EXE,\nDownload and extract git repository.\nNavigate to [working directory](bin/PathPandem.Win10/)\n\nRun file PathPandem.exe.\n\nThis executable file cannot be copied to any another location,\nas its dependencies are packed in the same folder.\n\n## Linux\n### Recommended:\nUse `pip` method as described below.\n\n### Else,\nUse generic method\n\n## Generic: From the source-code\n1. Download and unzip the git repository.\n   - Using git.\n```\ngit clone https://github.com/pradyparanjpe/PathPandem\n```\n2. Confirm pre-requisites.\n3. In Command Line/Shell, navigate to the repository folder and run\n```\npython bin/PathPandem\n```\n\n### Pre-requisites for running from the source-code:\n1. Python3.6 or higher\n2. Numpy >= 1.18\n3. Matplotlib >= 3.2.1\n4. Gooey >= [1.0.3](https://github.com/chriskiehl/Gooey)\n\n*1 can be installed from official source;\nfurther, 2, 3, 4 can be installed by command `pip install <module>`*.\n\n## pip\n1. Install python3 from [official website](https://www.python.org/downloads/)\n   - For Windows, enable \"Add to PATH environment variable\" during installation. (Recommended) install from Windows Store.\n   - This may require Root/Administrative privileges.\n2. Install PathPandem by typing in CommandPrompt/ Shell:\n\n```\npip install --user PathPandem\n```\n\n3. Run by typing in CommandPrompt/ Shell:\n\n```\npython -m \"PathPandem\"\n\n```\n\n*On Unix-like systems, the file `bin/PathPandem` is executable.*\n\n# Uninstallation\n\n### If installed by `pip`\n1. In CommandPrompt/Shell, type\n```\npip uninstall PathPandem\n```\n2. If not needed, remove python [like any regular program]\n\n### If installed by cloning git repo:\n1. Delete repository folder\n2. If not needed, remove python [like any regular program]\n\n### If Windows 10 folder was downloaded\n1. Delete folder\n\n\n# Updates:\n\n### If installed by `pip`\n1. In CommandPrompt/Shell, type\n```\npip install --upgrade PathPandem\n```\n\n### If installed by cloning git repo:\n1. In CommandPrompt/Shell, navigate inside the repo folder\n2. Type\n```\ngit pull\n```\n\n### If Windows 10 folder was downloaded\n1. Consider the option of deleting the folder and installation via `pip` or `git`\n2. If you *still insist* on EXE, delete the previous folder and download updated folder from git repository.\n\n*Back-up files before deleting the previous version. Recurrent downloads may consume a lot of Internet-Data.*\n\n\n# Known Issues:\n1. Python2's end-of-life was 2019-12-31.\n   - If `python` means `python2` on an operating system, most commonly due to an earlier-installed `python2`, try migrating to `python3` (recommended), or if you understand what you are doing, install `python3` alongside and run all commands with explicit mention of python3: `python3`, `pip3`, etc.\n2. wxPython currently fails installation via `pip`, [at least] on Linux.\n   - Install it using a package-manager (dnf, pacman, apt[, brew, chocolate,] etc) or manually before `pip` tries to install Gooey`.\n\n# Plot Legend:\n## Background Colour:\n### Movements\n- Green: No restrictions on movement.\n- Red: Lockdown Imposed.\n\n### Medical Progress\n- Blue: Drug discovered.\n- Cyan: Vaccine discovered.\n\n### Combinations\n- Grey: Red + Cyan.\n- Magenta: Red + Blue.\n- (*Any other standard RGB combinations*).\n\n# Caution:\n1. Population more than 10000 may stall the system.\n2. Tested only on Linux running from source-code.\n3. *True* numbers are plotted. However in reality, infection manifests symptoms after an initial lag of 1-3 days and test results appear further later by 1-2 days. Hence, graph trends need be imagined as having shifted suitably.\n4. Visualization is recommended only with very small population size.\n5. Although Infection may appear to exhaust in small sized, limited population; in reality, due to birth of new individuals, and in a very large population, the pathogen persists around at extemely low density.\n6. With small population size, random fluctuations become impactful. Multiple runs with same parameters are recommended.\n\n# Composition of scenario:\n- The GUI only edits the blanket population behaviour.\n- A heterogenous population can be composed using basic Python scripting in the `spread_simul.py` to construct heterogenously behaving population.\n\n# TODO:\n- Replace unimodal movement of people around their home to bimodal movement between home and workplace.\n- Parallelize numpy matrix `ufuncs` if possible.\n- Include asymptomatic patients/carriers. Limit movement of serious cases [although this won't have a visible effect for diseases with majority of cases being mild].\n- Animation, saved as mp4 for review\n\n# Brief epidemiological explanation:\n- Herd immunity starts reducing viral presence in community after viral steady state. i.e. plot of *Active* patients flattens. This happens when [1 - (1/R_{0})] fraction of the community becomes resistant. (Through vaccination or exposure)\n- Medicine development is fairly a rare event given the rightful stringency involved in testing.\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 56,
        "query": "**THIS PROJECT IS UNMAINTAINED**\n\nPlease use `micawber <https://github.com/coleifer/micawber>`_ -- it has much\nof the same functionality along with many improvements.\n\n\nGetting Started with OEmbed\n===========================\n\nInstallation\n------------\n\nFirst, you need to install OEmbed.  It is available at http://github.com/worldcompany/djangoembed/\n\n::\n\n    git clone git://github.com/worldcompany/djangoembed/\n    cd djangoembed\n    python setup.py install\n\nAdding to your Django Project\n--------------------------------\n\nAfter installing, adding OEmbed consumption to your projects is a snap.  First,\nadd it to your projects' INSTALLED_APPs and run 'syncdb'::\n    \n    # settings.py\n    INSTALLED_APPS = [\n        ...\n        'oembed'\n    ]\n\ndjangoembed uses a registration pattern like the admin's.  In order to be\nsure all apps have been loaded, djangoembed should run autodiscover() in the\nurls.py.  If you like, you can place this code right below your admin.autodiscover()\nbits::\n    \n    # urls.py\n    import oembed\n    oembed.autodiscover()\n\nConsuming Resources\n-------------------\n\nNow you're ready to start consuming OEmbed-able objects.  There are a couple of\noptions depending on what you want to do.  The most straightforward way to get\nup-and-running is to add it to your templates::\n\n    {% load oembed_tags %}\n    \n    {% oembed %}blog.content{% endoembed %}\n\n    {# or use the filter #}\n    \n    {{ blog.content|oembed }}\n    \n    {# maybe you're working with some dimensional constraints #}\n    \n    {% oembed \"600x600\" %}blog.content{% endoembed %}\n    \n    {{ blog.content|oembed:\"600x600\" }}\n\nYou can consume oembed objects in python as well::\n\n    import oembed\n    oembed.autodiscover()\n    \n    # just get the metadata\n    resource = oembed.site.embed('http://www.youtube.com/watch?v=nda_OSWeyn8')\n    resource.get_data()\n    \n    {u'author_name': u'botmib',\n     u'author_url': u'http://www.youtube.com/user/botmib',\n     u'height': 313,\n     u'html': u'<object width=\"384\" height=\"313\"><param name=\"movie\" value=\"http://www.youtube.com/v/nda_OSWeyn8&fs=1\"></param><param name=\"allowFullScreen\" value=\"true\"></param><param name=\"allowscriptaccess\" value=\"always\"></param><embed src=\"http://www.youtube.com/v/nda_OSWeyn8&fs=1\" type=\"application/x-shockwave-flash\" width=\"384\" height=\"313\" allowscriptaccess=\"always\" allowfullscreen=\"true\"></embed></object>',\n     u'provider_name': u'YouTube',\n     u'provider_url': u'http://www.youtube.com/',\n     u'title': u'Leprechaun in Mobile, Alabama',\n     u'type': u'video',\n     u'version': u'1.0',\n     u'width': 384}\n    \n    # get the metadata and run it through a template for pretty presentation\n    from oembed.consumer import OEmbedConsumer\n    client = OEmbedConsumer()\n    embedded = client.parse_text(\"http://www.youtube.com/watch?v=nda_OSWeyn8\")\n    \n    <div class=\"oembed oembed-video provider-youtube\">\n      <object width=\"384\" height=\"313\">\n        <param name=\"movie\" value=\"http://www.youtube.com/v/nda_OSWeyn8&fs=1\"></param>\n        <param name=\"allowFullScreen\" value=\"true\"></param>\n        <param name=\"allowscriptaccess\" value=\"always\"></param>\n        <embed src=\"http://www.youtube.com/v/nda_OSWeyn8&fs=1\" \n               type=\"application/x-shockwave-flash\" \n               width=\"384\" \n               height=\"313\" \n               allowscriptaccess=\"always\" \n               allowfullscreen=\"true\">\n        </embed>\n      </object>\n      <p class=\"credit\">\n        <a href=\"http://www.youtube.com/watch?v=nda_OSWeyn8\">Leprechaun in Mobile, Alabama</a>\n        by \n        <a href=\"http://www.youtube.com/user/botmib\">botmib</a>\n      </p>\n    </div>'\n\nTroubleshooting\n---------------\n\nProblem: You try the youtube embed example, but all you get is a link to the youtube video.\n\nSolution: Djangoembed uses fixtures to load data about oembed providors like Youtube in to the database.  Try fooling around with syncdb (or migrations, if you're running South) until there are objects of type oembed.storedprovider.\n\nIf you have another problem, consider looking through the more extensive docs in the project's doc subdirectory.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 57,
        "query": "This library is unmaintained now and it doesn't work with recent\n```libnetfilter_conntrack``` versions.\n\nI want to rewrite it using cython, but don't know when.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 58,
        "query": "==============\ndjango-rq-mail\n==============\n\n**This project is not maintained anymore, it doesn't support latest changes from rq**\n\ndjango-rq-mail is a simple Python library based on rq_ to store emails sent\nby Django_ and process them in the background with workers.\n\nAs django-rq-mail is based on rq_, it's entirely backed by Redis_.\n\nArchitecture\n------------\n\ndjango-rq-mail adds new elements to enjoy `Sorted Sets <http://redis.io/commands#sorted_set>`_\nfrom Redis_.\n\nFor the purpose of django-rq-mail, it implements the concept of ``WaitingQueue``\nwhich delays the processing of a job with a timestamp.\n\nThe default behavior of rq_ is to process jobs via `BLPOP <http://redis.io/commands/blpop>`_ which\nblocks the connection when there are no elements to pop from any of the given queues.\nWith this behavior there is no way to delays the processing of a job and when it's failing\nrq_ pushs it in a failed queue.\nOf course, you can requeue this job later but there is no fallback mechanism.\n\nIn django-rq-mail you can define fallback steps (in seconds) to retry a job until\nit's not failing. When a job has been tested on each steps we reintroduce\nthe default behavior of rq_ on pushing it in the failed queue.\n\nEach steps will create a waiting queue and when a job is failing we take the\ncurrent timestamp with the delta to retry it in the future.\n\n.. image:: http://yuml.me/895ce159\n\nThis mechanism is possible with `ZADD <http://redis.io/commands/zadd>`_ which\nadds a serialized job in the queue with a score and `ZREVRANGEBYSCORE <http://redis.io/commands/zrevrangebyscore>`_\nto return all the elements in the sorted set with a score between max (current timestamp) and min.\n\nAs you may understood, we have dropped the default blocking behavior\nto replace it by a daemon which is running each seconds.\n\n\nInstallation\n------------\n\n1. Either check out the package from GitHub_ or it pull from a release via PyPI ::\n\n       pip install django-rq-mail\n\n\n2. Add 'rq_mail' to your ``INSTALLED_APPS`` ::\n\n       INSTALLED_APPS = (\n           'rq_mail',\n       )\n\nto use the `rq_mail` command (via Django commandline) shipped by django-rq-mail.\n\nThis command is a minimal integration of rq_ into Django_ to launch the\n**Dispatcher**.\n\n3. Define ``EMAIL_BACKEND`` ::\n\n       EMAIL_BACKEND = 'rq_mail.backends.RqBackend'\n\n4. Define ``RQ_MAIL_EMAIL_BACKEND`` the backend used to send your emails, for example ::\n\n       RQ_MAIL_EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'\n\nLogging\n-------\n\nRQ 0.3.3 uses standard Python's ``logging``, this means\nyou can easily configure ``rqworker``'s logging mechanism in django's\n``settings.py``. For example:\n\n.. code-block:: python\n\n    LOGGING = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'formatters': {\n            'rq_console': {\n                'format': '%(asctime)s %(message)s',\n                'datefmt': '%H:%M:%S',\n            },\n        },\n        'handlers': {\n            'rq_console': {\n                'level': 'DEBUG',\n                'class': 'rq.utils.ColorizingStreamHandler',\n                'formatter': 'rq_console',\n                'exclude': ['%(asctime)s'],\n            },\n        },\n        'loggers': {\n            'rq.worker': {\n                'handlers': ['rq_console'],\n                'level': 'DEBUG'\n            },\n        }\n    }\n\nUtilisation\n-----------\n\nOnce you have installed it, you can run ``python manage.py rq_mail`` from your shell.\n\nConfiguration\n-------------\n\n``RQ_MAIL_PREFIX``\n..................\n\nThe prefix used to name all queues created by django-rq-mail.\n\n``RQ_MAIL_MAIN_QUEUE``\n......................\n\nThe name of the main queue.\n\n``RQ_MAIL_EMAIL_BACKEND``\n.........................\n\nThe email backend used to send emails when they are processed in the background.\n\n``RQ_MAIL_REDIS_HOST``\n......................\n\nThe Redis host used to connect.\n\n``RQ_MAIL_REDIS_PORT``\n......................\n\nThe Redis port used to connect.\n\n``RQ_MAIL_REDIS_DB``\n....................\n\nThe Redis database used to connect.\n\n``RQ_MAIL_REDIS_PASSWORD``\n..........................\n\nThe Redis password used to connect.\n\n``RQ_MAIL_REDIS_URL``\n..........................\n\nThe Redis url used to connect.\n\n``RQ_MAIL_REDIS_SOCKET``\n..........................\n\nThe Redis socket used to connect.\n\n``RQ_MAIL_FALLBACK_STEPS``\n..........................\n\nA simple list of timing to create waiting queues.\n\nYou can define as much steps as you want, each will be transformed to a queue.\nSo if you define 10 steps, you will allow a message to fail 10 times until it\nwill go in the failed queue.\n\n.. _Django: https://www.djangoproject.com/\n.. _rq: https://github.com/nvie/rq\n.. _Redis: http://redis.io/\n.. _GitHub: https://github.com/thoas/django-rq-mail\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 59,
        "query": "### Note: this project is deprecated. \n\nIn RDFLib >= 4.0, rdfextras is no longer required, SPARQL support and the utilities from this project are included in core.\n\n\n========================================================================\nRDFExtras README\n========================================================================\n\nRDFExtras is a collection of packages providing extras based on RDFLib. These\ninclude a tools package and several \"non-core-rdflib\" store implementations.\n\nRDFExtras includes: \n\n * A pure-python SPARQL implementation for in-memory stores or other store\n   that do not provide their own SPARQL implementation. \n * A set of commandline utilities: rdfpipe, rdf2dot, rdfs2dot, csv2rdf\n\nDependencies: \n\n * RDFLib>=3.2.1\n * For SPARQL: pyparsing\n\nFor more information see: \n * RDFExtras: http://github.com/RDFLib/rdfextras/\n * RDFExtras Docs: http://readthedocs.org/docs/rdfextras/\n \n * RDFLib: http://github.com/RDFLib/rdflib/\n * RDFLib Docs: http://readthedocs.org/docs/rdflib\n\n * Discussion group: http://groups.google.com/group/rdflib-dev\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 60,
        "query": ".. _jingo:\n.. module:: jingo\n\n=====\nJingo\n=====\n\nJingo is an adapter for using Jinja2_ templates within Django.\n\n\nJingo is DEPRECATED\n-------------------\n\nIn version 1.8, Django added support for multiple template engines, and provided\na Jinja2 backend.  The django-jinja_ project leverages that to support Jinja2,\nwhile Jingo does not.\n\n**django-jinja is recommended for new projects.** Jingo >=0.8 supports Django\n1.8, but it will not be maintained beyond version 0.9, and **will not** support\nDjango 1.9 or above.  If you're already using Jingo, and not ready to make `the\nswitch`_, Jingo should continue to work for now, though not without some effort.\n\n0.9_ will be the last release of Jingo, unless a new maintainer comes along with\na new direction.\n\nAs of 0.9, Jingo's built-in helpers are provided via a `Jinja2 extension`_ to\nsimplify moving away from Jingo. The entire ``jingo/ext.py`` file can be copied\ninto another project, or referenced as ``'jingo.ext.JingoExtension'``. Used in\nthis way, Jingo plays nicely with django-jinja (and theoretically Django's\nbuilt-in Jinja2 backend).\n\n.. _django-jinja: https://github.com/niwinz/django-jinja\n.. _the switch: http://bluesock.org/~willkg/blog/mozilla/input_django_1_8_upgrade.html#switching-from-jingo-to-django-jinja\n.. _Jinja2: http://jinja.pocoo.org/2/\n.. _0.9: https://https://pypi.python.org/pypi/jingo/0.9.0\n.. _Jinja2 extension: https://github.com/jbalogh/jingo/blob/master/jingo/ext.py\n\n\n.. _usage:\n\nUsage\n-----\n\nWhen configured properly (see Settings_ below) you can render Jinja2_ templates in\nyour view the same way you'd render Django templates::\n\n    from django.shortcuts import render\n\n\n    def my_view(request):\n        context = dict(user_ids=(1, 2, 3, 4))\n        return render(request, 'users/search.html', context)\n\n.. note::\n\n    Not only does ``django.shorcuts.render`` work, but so does any method that\n    Django provides to render templates.\n\n.. _settings:\n\nSettings\n--------\n\nYou'll want to use Django to use jingo's template loader.\nIn ``settings.py``::\n\n    TEMPLATE_LOADERS = (\n        'jingo.Loader',\n        'django.template.loaders.filesystem.Loader',\n        'django.template.loaders.app_directories.Loader',\n    )\n\nThis will let you use ``django.shortcuts.render`` or\n``django.shortcuts.render_to_response``.\n\nYou can optionally specify which filename patterns to consider Jinja2 templates::\n\n    JINGO_INCLUDE_PATTERN = r'\\.jinja2'  # use any regular expression here\n\nThis will consider every template file that contains the substring `.jinja2` to\nbe a Jinja2 file (unless it's in a module explicitly excluded, see below).\n\nAnd finally you may have apps that do not use Jinja2, these must be excluded\nfrom the loader::\n\n    JINGO_EXCLUDE_APPS = ('debug_toolbar',)\n\nIf a template path begins with ``debug_toolbar``, the Jinja loader will raise a\n``TemplateDoesNotExist`` exception. This causes Django to move onto the next\nloader in ``TEMPLATE_LOADERS`` to find a template - in this case,\n``django.template.loaders.filesystem.Loader``.\n\n.. note::\n   Technically, we're looking at the template path, not the app. Often these are\n   the same, but in some cases, like 'registration' in the default setting--which\n   is an admin template--they are not.\n\nThe default is in ``jingo.EXCLUDE_APPS``::\n\n    EXCLUDE_APPS = (\n        'admin',\n        'admindocs',\n        'registration',\n        'context_processors',\n    )\n\n.. versionchanged:: 0.6.2\n   Added ``context_processors`` application.\n\nIf you want to configure the Jinja environment, use ``JINJA_CONFIG`` in\n``settings.py``.  It can be a dict or a function that returns a dict. ::\n\n    JINJA_CONFIG = {'autoescape': False}\n\nor::\n\n    def JINJA_CONFIG():\n        return {'the_answer': 41 + 1}\n\nIf you set the ``extensions`` key in the configuration, you **must**\ninclude ``jingo.ext.JingoExtension`` to get Jingo's built-in template\nhelpers (see below).\n\n\nTemplate Helpers\n----------------\n\n.. note::\n\n    In the interest of future-proofing, consider writing custom filters and\n    functions as Jinja extensions. See ``jingo/ext.py`` for a simple example.\n\nInstead of template tags, Jinja encourages you to add functions and filters to\nthe templating environment.  In ``jingo``, we call these helpers.  When the\nJinja environment is initialized, ``jingo`` will try to open a ``helpers.py``\nfile from every app in ``INSTALLED_APPS``.  Two decorators are provided to ease\nthe environment extension:\n\n.. function:: jingo.register.filter\n\n    Adds the decorated function to Jinja's filter library.\n\n.. function:: jingo.register.function\n\n    Adds the decorated function to Jinja's global namespace.\n\n\nDefault Helpers\n~~~~~~~~~~~~~~~\n\nHelpers are available in all templates automatically, without any extra\nloading. See ``jingo/ext.py`` for their definitions.\n\n\nTemplate Environment\n--------------------\n\nA single Jinja ``Environment`` is created for use in all templates.  This is\navailable via ``jingo.get_env()`` if you need to work with the ``Environment``.\n\n\nLocalization\n------------\n\nSince we all love L10n, let's see what it looks like in Jinja templates::\n\n    <h2>{{ _('Reviews for {0}')|f(addon.name) }}</h2>\n\nThe simple way is to use the familiar underscore and string within a ``{{ }}``\nmoustache block.  ``f`` is an interpolation filter documented below.  Sphinx\ncould create a link if I knew how to do that.\n\nThe other method uses Jinja's ``trans`` tag::\n\n    {% trans user=review.user|user_link, date=review.created|datetime %}\n        by {{ user }} on {{ date }}\n    {% endtrans %}\n\n``trans`` is nice when you have a lot of text or want to inject some variables\ndirectly.  Both methods are useful, pick the one that makes you happy.\n\n\nForms\n-----\n\nDjango marks its form HTML \"safe\" according to its own rules, which Jinja2 does\nnot recognize.\n\nThis monkeypatches Django to support the ``__html__`` protocol used in Jinja2\ntemplates. ``Form``, ``BoundField``, ``ErrorList``, and other form objects that\nrender HTML through their ``__unicode__`` method are extended with ``__html__``\nso they can be rendered in Jinja2 templates without adding ``|safe``.\n\nCall the ``patch()`` function to execute the patch. It must be called\nbefore ``django.forms`` is imported for the conditional_escape patch to work\nproperly. The root URLconf is the recommended location for calling ``patch()``.\n\nUsage::\n\n    import jingo.monkey\n    jingo.monkey.patch()\n\n\nTesting\n-------\n\nTo run the test suite, you need to define ``DJANGO_SETTINGS_MODULE`` first::\n\n    $ export DJANGO_SETTINGS_MODULE=\"fake_settings\"\n    $ nosetests\n\nor simply run::\n\n    $ python run_tests.py\n\nTo test on all supported versions of Python and Django::\n\n    $ pip install tox\n    $ tox\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 61,
        "query": "DEPRECATED, USE `DJANGO-USERPROFILE <https://github.com/praekelt/django-userprofile>`_ INSTEAD!\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 62,
        "query": "========\nbarbeque\n========\n\n.. image:: https://badge.fury.io/py/barbeque.png\n    :target: http://badge.fury.io/py/barbeque\n    :alt: Latest PyPI version\n\n.. image:: https://travis-ci.org/moccu/barbeque.png?branch=master\n    :target: https://travis-ci.org/moccu/barbeque\n    :alt: Latest Travis CI build status\n\n.. image:: https://coveralls.io/repos/moccu/barbeque/badge.svg\n    :target: https://coveralls.io/github/moccu/barbeque\n    :alt: Coverage of master build\n\n.. image:: https://readthedocs.org/projects/barbeque/badge/?version=latest\n    :target: http://barbeque.readthedocs.org/en/latest/\n    :alt: Latest read the docs build\n\nBarbeque is a collection of custom extensions and helpers, mostly related to the Django Web framework.\n\nThese include a commands framework, logging helpers, django-anylink, filer extensions and much much more.\n\n\nbarbeque is deprecated\n======================\n\nPlease use following libraries instead:\n\n* `django-cms-helpers <https://github.com/moccu/django-cms-helpers>`_\n* `django-exporter <https://github.com/moccu/django-exporter>`_\n* `django-inline-static <https://github.com/moccu/django-inline-static>`_\n* `django-static-delivery <https://github.com/moccu/django-static-delivery>`_\n* `django-static-templates <https://github.com/moccu/django-static-templates>`_\n* `django-template-helpers <https://github.com/moccu/django-template-helpers>`_\n* `python-command-executor <https://github.com/moccu/python-command-executor>`_\n\n\nFeatures\n========\n\n* Commands framework\n* Logging helpers\n* django-anylink and django-cms extensions\n* django-filer extensions\n* various helpers for forms and generic views\n\n\nResources\n=========\n\n* `Documentation <https://barbeque.readthedocs.org/>`_\n* `Bug Tracker <https://github.com/moccu/barbeque/issues>`_\n* `Code <https://github.com/moccu/barbeque/>`_\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 63,
        "query": "=========================================================\ndjango-kombu - Kombu transport using the Django database.\n=========================================================\n\n:version: 0.9.4\n\nDeprecated\n==========\n\ndjango-kombu has now moved into Kombu core, so this repository\nis no longer in use.\n\nTo upgrade, install the latest Kombu version and add the following\nto your settings.py::\n\n    INSTALLED_APPS = (\n        \"kombu.transport.django\",\n    )\n\nYou can remove the previous \"djkombu\" entry.\n\n\n**ORIGINAL README BELOW**\n\n\nIntroduction\n============\n\nThis package enables you to use the Django database as the message store\nfor `Kombu`_.\n\n\nTo use you first have to add ``djkombu`` to ``INSTALLED_APPS``, and then\nexecute ``syncdb`` to create the tables.\n\n``django-kombu`` contains a single transport,\n``djkombu.transport.DatabaseTransport``, which is used like this::\n\n    >>> from kombu.connection import BrokerConnection\n    >>> c = BrokerConnection(transport=\"djkombu.transport.DatabaseTransport\")\n\n\n.. _`Kombu`: http://pypi.python.org/pypi/kombu\n\nInstallation\n============\n\nYou can install ``django-kombu`` either via the Python Package Index (PyPI)\nor from source.\n\nTo install using ``pip``,::\n\n    $ pip install django-kombu\n\n\nTo install using ``easy_install``,::\n\n    $ easy_install django-kombu\n\n\nIf you have downloaded a source tarball you can install it\nby doing the following,::\n\n    $ python setup.py build\n    # python setup.py install # as root\n\nLicense\n=======\n\nThis software is licensed under the ``New BSD License``. See the ``LICENSE``\nfile in the top distribution directory for the full license text.\n\n.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 64,
        "query": "sentry-jira\n===========\n\n**DEPRECATED:** This project now lives in `sentry-plugins <https://github.com/getsentry/sentry-plugins>`_\n\nA flexible extension for Sentry which allows you to create issues in JIRA based on sentry events.\nIt is capable of rendering and saving many custom fields, and will display the proper fields depending on\nwhich issue type you are trying to create.\n\n**Requires Sentry 8+**\n\nInstallation\n------------\n\nInstall the package via ``pip``:\n\n::\n\n    pip install sentry-jira\n\nConfiguration\n-------------\n\nGo to your project's configuration page (Dashboard -> [Project] -> Settings), select the\nIssue Tracking tab, and then click the JIRA button under available integrations.\n\nEnter the JIRA credentials and Project configuration and save changes. Filling out the form is\na two step process (one to fill in data, one to enter additional options).\n\nMore Documentation\n------------------\n\nHave a look at the readthedocs page for more detailed configuration steps and a\nchangelog: https://sentry-jira.readthedocs.io/en/latest/\n\nLicense\n-------\n\nsentry-jira is licensed under the terms of the 3-clause BSD license.\n\nContributing\n------------\n\nAll contributions are welcome, including but not limited to:\n\n - Documentation fixes / updates\n - New features (requests as well as implementations)\n - Bug fixes (see issues list)\n - Update supported JIRA types as you come across them\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 65,
        "query": "# dPayLib (Python)\n\nThis library is unmaintained, do not build productive buisness with it!\nPlease not the disclaimer in the license file!\n\n\nPython Library for dPay\n========================\n\nPython 3 library for dPay!\n\nInstallation\n------------\n\nInstall with `pip3`:\n\n    $ sudo apt-get install libffi-dev libssl-dev python-dev python3-pip\n    $ pip3 install dpay-lib\n\nManual installation:\n\n    $ git clone https://github.com/dpays/dpay-python-lib/\n    $ cd dpay-python-lib\n    $ python3 setup.py install --user\n\nUpgrade\n-------\n\n    $ pip3 install dpay --user --upgrade\n\nAdditional dependencies\n-----------------------\n\n`dpayapi.dpayasyncclient`:\n * `asyncio==3.4.3`\n * `pyyaml==3.11`\n\nDocumentation\n-------------\n\nDocumentation is written with the help of sphinx and can be compile to\nhtml with:\n\n    cd docs\n    make html\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 66,
        "query": "Serverless Helpers (Python Version)\n=================================\n\n:warning: Deprecated for Serverless 0.5+ users\n\n###Features\n* Helps your modules locate and load Stage Variables that the Serverless framework adds on deployment.\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 67,
        "query": ".. This README is meant for consumption by humans and pypi. Pypi can render rst files so please do not use Sphinx features.\n   If you want to learn more about writing documentation, please check out: http://docs.plone.org/about/documentation_styleguide.html\n   This text does not appear on pypi or github. It is a comment.\n\n==============================================================================\nredturtle.agidtheme\n==============================================================================\n\n\n   **WARNING!**\n\n   **DEPRECATED** in favor of https://github.com/italia/design.plone.theme\n\n\n\n\nIl primo tema Plone conforme a `Italia design system`__.\n\n__ https://design-italia.readthedocs.io/it/stable/index.html\n\nQuesto tema si basa sulla versione 2017.1 delle linee guida.\n\n|\n\nThis is the first Plone theme that is compliant with the `Italia design system`__ guidelines.\n\n__ https://design-italia.readthedocs.io/it/stable/index.html\n\nIt is built on guidelines' version 2017.1.\n\nThis README is written in italian language because it's meant for Italian Public Administration websites.\n\n\nDocumentazione\n--------------\n\nLa documentazione per l'utente finale \u00e8 disponibile in `questo documento`__.\n\n__ https://docs.google.com/document/d/1ncSgzj0JABBWR1Jt7sxtIH5qwjCVN10qBm7uA8uM5cw/export?format=pdf\n\n\nEsempi\n------\n\nQuesto tema pu\u00f2 essere visto in azione nei seguenti siti web:\n\n- `digitale.regione.emilia-romagna.it`__\n- `regione.emilia-romagna.it`__\n- `comune.santarcangelo.rn.it`__\n- `comune.calderaradireno.bo.it`__\n\n__ http://digitale.regione.emilia-romagna.it\n__ http://www.regione.emilia-romagna.it\n__ http://www.comune.santarcangelo.rn.it\n__ http://www.comune.calderaradireno.bo.it\n\n\nTraduzioni\n-----------\n\nQuesto prodotto \u00e8 stato tradotto nelle seguenti lingue:\n\n- Italiano\n\n\nInstallazione\n-------------\n\nInstalla redturtle.agidtheme aggiungendolo al tuo buildout::\n\n    [buildout]\n\n    ...\n\n    eggs =\n        redturtle.agidtheme\n\n\ne successivamente eseguendo ``bin/buildout``.\n\nAl successivo avvio del sito troverete il tema disponibile tra i prodotti aggiuntivi del sito, con il nome \"Tema: Italia design system\".\n\n\nSviluppo\n--------\n\nPer la compilazione del codice Sass e la build del bundle JavaScript, sono presenti alcuni script nel ``package.json``:\n\n- ``yarn develop``: esegue la compilazione con grunt e lo lascia avviato in modalit\u00e0 watch\n- ``yarn build``: compila con grunt e esegue prettier\n- ``yarn test``: esegue il linting con stylelint.\n\n\nCompatibilit\u00e0\n-------------\n\nQuesto prodotto \u00e8 stato testato su Plone >= 5.0.7.\n\n\nRiconoscimenti\n--------------\n\nSviluppato con il supporto di `Regione Emilia-Romagna`__.\n\n__ http://www.regione.emilia-romagna.it/\n\n\n\nAutori\n------\n\nQuesto prodotto \u00e8 stato sviluppato dal team di RedTurtle Technology.\n\n.. image:: http://www.redturtle.it/redturtle_banner.png\n   :alt: RedTurtle Technology Site\n   :target: http://www.redturtle.it/\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 68,
        "query": "# Pyrallel - Parallel Data Analytics in Python\n\n**Unmaintained warning**: this project has no future, use [dask](\nhttps://dask.pydata.org/en/latest/) and `dask-distributed` instead.\n\n\n**Overview**: experimental project to investigate distributed computation\npatterns for machine learning and other semi-interactive data analytics\ntasks.\n\n**Scope**:\n\n- focus on small to medium dataset that fits in memory on a small\n  (10+ nodes) to medium cluster (100+ nodes).\n\n- focus on small to medium data (with data locality when possible).\n\n- focus on CPU bound tasks (e.g. training Random Forests) while trying to\n  limit disk / network access to a minimum.\n\n- do not focus on HA / Fault Tolerance (yet).\n\n- do not try to invent new set of high level programming abstractions\n  (yet): use a low level programming model (IPython.parallel) to finely\n  control the cluster elements and messages transfered and help identify\n  what are the practical underlying constraints in distributed machine\n  learning setting.\n\n\n**Disclaimer**: the public API of this library will probably not be\nstable soon as the current goal of this project is to experiment.\n\n\n## Dependencies\n\nThe usual suspects: Python 2.7, NumPy, SciPy.\n\nFetch the development version (master branch) from:\n\n- https://github.com/ipython/ipython\n\n- https://github.com/scikit-learn/scikit-learn\n\nStarCluster `develop` branch and its `IPCluster` plugin is also required\nto easily startup a bunch of nodes with IPython.parallel setup.\n\n## Patterns currently under investigation\n\n- Asynchronous & randomized hyper-parameters search (a.k.a. Randomized Grid\n  Search) for machine learning models\n\n- Share numerical arrays efficiently over the nodes and make them\n  available to concurrently running Python processes without making\n  copies in memory using memory-mapped files.\n\n- Distributed Random Forests fitting.\n\n- Ensembling heterogeneous library models.\n\n- Parallel implementation of online averaged models using a MPI AllReduce, for\n  instance using MiniBatchKMeans on partitioned data.\n\n\nSee the content of the `examples/` folder for more details.\n\n\n## License\n\nMIT\n\n\n## History\n\nThis project started at the [PyCon 2012 PyData\nsprint](http://wiki.ipython.org/PyCon12Sprint)\nas a set of proof of concept [IPython.parallel\nscripts](https://github.com/ogrisel/pycon-pydata-sprint).\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 69,
        "query": "Deprecation Notice\n==================\n\nThis code is deprecated, the current version of Bitmask is developed in the `bitmask-dev`_ repo.\n\n.. _`bitmask-dev`: https://0xacab.org/leap/bitmask-dev\n\nleap.mail\n=========\nMail services for the LEAP Client.\n\n.. image:: https://badge.fury.io/py/leap.mail.svg\n    :target: http://badge.fury.io/py/leap.mail\n\n.. image:: https://readthedocs.org/projects/leapmail/badge/?version=latest\n         :target: http://leapmail.readthedocs.org/en/latest/\n         :alt: Documentation Status\n\nMore info: https://leap.se\n\nrunning tests\n-------------\n\nUse trial to run the test suite::\n\n  trial leap.mail\n\n... and all its goodies. To run all imap tests in a loop until some of them\nfails::\n\n  trial -u leap.mail.imap\n\nRead the *trial* manpage for more options .\n\nimap regressions\n----------------\n\nFor testing the IMAP server implementation, there are a couple of utilities.\nFrom the ``leap.mail.imap.tests`` folder, and with an already initialized server\nrunning::\n\n  ./regressions_mime_struct user@provider pass path_to_samples/\n\nYou can find several message samples in the ``leap/mail/tests`` folder.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 70,
        "query": "THIS REPO IS NO LONGER SUPPORTED. IF YOU ARE LOOKING FOR A SIMILAR SOLUTION, WE WOULD RECOMMEND LOOKING AT https://github.com/jamesls/fakeredis\n\n# Mock for the redis-py client library\n\nSupports writing tests for code using the [redis-py][redis-py] library\nwithout requiring a [redis-server][redis] install.\n\n[![Build Status](https://travis-ci.org/locationlabs/mockredis.png)](https://travis-ci.org/locationlabs/mockredis)\n\n## Installation\n\nUse pip:\n\n    pip install mockredispy\n\n## Usage\n\nBoth `mockredis.mock_redis_client` and `mockredis.mock_strict_redis_client` can be\nused to patch instances of the *redis client*.\n\nFor example, using the [mock][mock] library:\n\n    @patch('redis.Redis', mock_redis_client)\n\nOr:\n\n    @patch('redis.StrictRedis', mock_strict_redis_client)\n\n## Testing\n\nMany unit tests exist to verify correctness of mock functionality. In addition, most\nunit tests support testing against an actual redis-server instance to verify the tests\nagainst ground truth. See `mockredis.tests.fixtures` for more details and disclaimers.\n\n## Supported python versions\n\n - Python 2.7\n - Python 3.2\n - Python 3.3\n - Python 3.4\n - PyPy\n - PyPy3\n\n## Attribution\n\nThis code is shamelessly derived from work by [John DeRosa][john].\n\n [redis-py]: https://github.com/andymccurdy/redis-py\n [redis]:    http://redis.io\n [john]:     http://seeknuance.com/2012/02/18/replacing-redis-with-a-python-mock/\n [mock]:     http://www.voidspace.org.uk/python/mock/\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 71,
        "query": "**Warning**: This repository is now **DEPRECATED**. This library is deprecated\nand no longer maintained.\n\nIt has been superseded by the `bob.bio` packages, which can be [downloaded from\nPyPI](http://pypi.python.org/pypi/bob.bio.base). These packages are direct\nsuccessors of this library and `bob.spear`, incorporating a *broader* set\nfunctionality to run biometric recognition algorithms in general. Please read\nthe [documentation of the bob.bio\npackages](http://pythonhosted.org/bob.bio.base/index.html), particularly the\n[installation\ninstructions](http://pythonhosted.org/bob.bio.base/installation.html).\n\nAs a side note, notice Bob is now maintained in\n[Gitlab](https://gitlab.idiap.ch/groups/bob). Our\n[homepage](https://www.idiap.ch/software/bob/) continues active and will\nre-direct you to up-to-date links. Don't report issues here, post them together\nwith your questions at [mailing\nlist](https://www.idiap.ch/software/bob/discuss).\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 72,
        "query": "# --------------------- * DEPRECATED * --------------------- \n- This Library was integrated into AzureRM code <a href=\"https://github.com/gbowerman/azurerm\">here</a>.\n- For full examples you can download/fork my git repo <a href=\"https://github.com/msleal/azurerm\">here</a>.\n# --------------------- * DEPRECATED * --------------------- \n\n## Simple Python Library for Azure Media Services REST API\nThe amspy is a library to provide a simple Azure Media Services REST interface for python. This is a personal project and NOT an official implementation of the Azure Media Services SDK for python. The only purpose of this library is for educational purposes, so people can have an easy way to understand how to interact with cloud REST apis, and learn from the examples provided in this module as well as the debug information available in the logs. Any feedback, comments or bugs, please send directly to the module owner, and go to https://azure.microsoft.com if you are looking for official Microsoft Azure SDKs.\n\n### Using AMSPy\nA detailed set of **amspy** programming examples can be found here: <a href=\"https://github.com/msleal/amspy/tree/master/amspy/examples\">AMSPy Python library programming examples</a>.\n\n#### Listing Media Assets:\n```\nimport os\nimport json\nimport amspy\n\n# Load Azure app defaults\ntry:\n        with open('config.json') as configFile:\n                configData = json.load(configFile)\nexcept FileNotFoundError:\n        print(\"ERROR: Expecting config.json in current folder\")\n        sys.exit()\n\naccount_name = configData['accountName']\naccount_key = configData['accountKey']\n\n# Get the access token...\nresponse = amspy.get_access_token(account_name, account_key)\nresjson = response.json()\naccess_token = resjson[\"access_token\"]\n\n### list media assets\nresponse = amspy.list_media_asset(access_token)\nif (response.status_code == 200):\n        resjson = response.json()\n        print(\"POST Status.....: \" + str(response.status_code))\n        for ma in resjson['d']['results']:\n                print(\"Media Asset Name: \" + ma['Id'])\n                print(\"Media Asset Id..: \" + ma['Name'])\nelse:\n        print(\"GET Status: \" + str(response.status_code) + \" ERROR:\" + str(response.content))\n```\n### Azure Media Analytics Usage Sample Scripts\nA set of scripts that show how to use Azure Media Analytics is available in the amspy/examples/analytics folder. \nIn this folder you will find examples of the following analytics tools:\n\n- Face Detection\n- Face Redaction\n- Hyperlapse\n- Indexer v1\n- Indexer v2 (Preview)\n- Motion Detection\n- OCR\n- Video Thumbnail\n\nEach of the samples includes a single Python script and configuration file for the processor.\nSimply execute the python script to process a source file. \nTo modify the source file used, edit the global variable and change the \nVIDEO_PATH to point to your source file. \n\nThe script will execute and download the output results of the Media Analytics job into the \"output\" folder in the example.\nYou can modify the settings files for each processor to adjust the output results.\n\nFor additional documentation about Azure Media Analytics, plese refer to the page http://aka.ms/mediaanalytics\n\nPlease contact us on Twitter -  @MSFTAzureMedia - if you have any questions.\n\n### AMSPy Library Functions:\n```\nadd_authorization_policy(access_token, ck_id, oid) - add authorization policy to key\ncreate_asset_accesspolicy(access_token, name, duration, permission=\"1\") - create an asset access policy\ncreate_asset_delivery_policy(access_token, ams_account) - create asset delivery policy\ncreate_contentkey_authorization_policy(access_token, content) - create contenty key authorization policy\ncreate_contentkey_authorization_policy_options(access_token, key_delivery_type=\"2\", name=\"HLS Open Authorization Policy\", key_restriction_type=\"0\") - create content key authorization policy options\ncreate_media_asset(access_token, name, options=\"0\") - create a media asset\ncreate_media_assetfile(access_token, parent_asset_id, name, is_primary=\"false\", is_encrypted=\"false\", encryption_scheme=\"None\", encryptionkey_id=\"None\") - create a media assetfile\ncreate_media_job(access_token, name, job_definition, processor_id, asset_id, task_body) -create a job\ncreate_media_task(access_token, name, processor_id, asset_id, content) - create a media task\ncreate_ondemand_streaming_locator(access_token, encoded_asset_id, pid, starttime=None) - create on-demand streaming locator\ncreate_sas_locator(access_token, asset_id, accesspolicy_id) - create a sas url locator\ncreate_streaming_endpoint(access_token, name, description=\"New Streaming Endpoint\", scale_units=\"1\") - create a streaming endpoint\ndelete_asset_accesspolicy(access_token, oid) - delete an asset acess policy\ndelete_asset_delivery_policy(access_token, oid) - delete media asset delivery policy\ndelete_content_key(access_token, oid) - delete an asset acess policy\ndelete_contentkey_authorization_policy(access_token, oid) - delete content key authorization policy\ndelete_contentkey_authorization_policy_options(access_token, oid) - delete content key authorization policy options\ndelete_media_asset(access_token, oid) - delete an asset\ndelete_sas_locator(access_token, oid) - delete a sas locator\ndelete_streaming_endpoint(access_token, oid) - delete a streaming endpoint\nencode_mezzanine_asset(access_token, processor_id, asset_id, output_assetname, json_profile) - encode a mezzanine (raw video) file into multi-bitrate MP4 video asset\nget_access_token(accountname, accountkey) - get the access token/authenticate\nget_delivery_url(access_token, ck_id, key_type) - get the key delivery url\nget_url(access_token, endpoint=ams_rest_endpoint, flag=True) - get a specific url\nlink_asset_content_key(access_token, asset_id, encryptionkey_id, ams_redirected_rest_endpoint) - link a content key with a media asset\nlink_asset_delivery_policy(access_token, asset_id, adp_id, ams_redirected_rest_endpoint) - link asset to delivery policy\nlink_contentkey_authorization_policy(access_token, ckap_id, options_id, ams_redirected_rest_endpoint) - link content key authorization policy\nlist_asset_accesspolicy(access_token, oid=\"\") - list asset access policy\nlist_asset_delivery_policy(access_token, oid=\"\") - list media asset delivery policy(ies)\nlist_content_key(access_token, oid=\"\") - list content key(s)\nlist_contentkey_authorization_policy(access_token, oid=\"\") - list content key authorization policy(ies)\nlist_contentkey_authorization_policy_options(access_token, oid=\"\") - list content key authorization policy options\nlist_media_asset(access_token, oid=\"\") - list media asset(s)\nlist_media_job(access_token, oid=\"\") - list media job(s)\nlist_media_processor(access_token, oid=\"\") - list media processor(s)\nlist_sas_locator(access_token, oid=\"\") - list sas locator(s)\nlist_streaming_endpoint(access_token, oid=\"\") - list streaming endpoint(s)\nretrieve_url_content(url) - get a specific url\nscale_streaming_endpoint(access_token, streaming_endpoint_id, scale_units) - scale a streaming endpoint\ntranslate_asset_options(nr) - translate the numeric configuration options of the asset to a human readable form\ntranslate_job_state(nr) - translate the numeric job state to a human readable form\nupdate_media_assetfile(access_token, parent_asset_id, asset_id, content_length, name) - update assetfile content length\nupload_block_blob(access_token, endpoint, content, content_length) - upload a file as a block blob\nvalidate_mp4_asset(access_token, processor_id, asset_id, output_assetname) - validade an encoded multi-bitrate MP4 asset\n```\n\n\n### Sample Movie clip in examples/assets folder:\nThe video file in \\examples\\analytics\\assets\\movie.mp4 is a clip from \"Tears of Steel\" courtesy of (CC) Blender Foundation | mango.blender.org\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 73,
        "query": "~~~~~~~~~~~~~~~~~\nepub-extract-jpeg\n~~~~~~~~~~~~~~~~~\n\n\nDEPRECATED!!!\n\nYou can use epub-extractor https://github.com/ytyng/epub-extractor .\n\n\nepub-extractor \u306b\u6a5f\u80fd\u304c\u53d6\u308a\u8fbc\u307e\u308c\u307e\u3057\u305f\n\n\nExtract Jpeg files in COMIC EPUB file,\n\n\nInstall\n-------\n\n::\n\n  $ pip install epub-extract-jpeg\n\n\nRequirements\n------------\n\n* unzip\n\n* PIL: convert PNG image to Jpeg.\n  with option `--no-convert-png` , cancelled.\n\n\nHow to use\n----------\n\n::\n\n  $ epub-extract-jpeg xxxx.epub\n\nCreate xxx directory, and extract images to there.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 74,
        "query": "PyEmbed\n=======\n\nProject status: unmaintained\n----------------------------\n\nThis project is no longer updated.  The code is here for historic purposes only.\n\n----\n\n.. image:: https://secure.travis-ci.org/pyembed/pyembed.png?branch=master\n  :target: http://travis-ci.org/pyembed/pyembed\n.. image:: https://coveralls.io/repos/pyembed/pyembed/badge.png\n  :target: https://coveralls.io/r/pyembed/pyembed\n.. image:: https://pypip.in/d/pyembed/badge.png\n  :target: https://pypi.python.org/pypi/pyembed/\n.. image:: https://pypip.in/v/pyembed/badge.png\n  :target: https://pypi.python.org/pypi/pyembed/\n.. image:: https://pypip.in/wheel/pyembed/badge.png\n  :target: https://pypi.python.org/pypi/pyembed/\n.. image:: https://pypip.in/egg/pyembed/badge.png\n  :target: https://pypi.python.org/pypi/pyembed/\n.. image:: https://pypip.in/license/pyembed/badge.png\n  :target: https://pypi.python.org/pypi/pyembed/\n\n`OEmbed`_ consumer library for Python with automatic discovery of\nproducers.\n\nPyEmbed allows you to easily embed content on your website from a wide\nvariety of producers (including `Flickr`_, `Twitter`_ and `YouTube`_).\nUnlike many OEmbed consumers, you don't need to configure each producer\nthat you want to use - PyEmbed discovers the configuration automatically.\n\nYou just need to provide the URL, and PyEmbed will generate a block of\nHTML, ready for you to include in your page:\n\n::\n\n    >>> from pyembed.core import PyEmbed\n    >>> html = PyEmbed().embed('http://www.youtube.com/watch?v=9bZkp7q19f0')\n    <iframe width=\"480\" height=\"270\" src=\"http://www.youtube.com/embed/9bZkp7q19f0?feature=oembed\" frameborder=\"0\" allowfullscreen></iframe>\n\nThere are plugins for embedding content into `Markdown`_ and \n`reStructuredText`_ documents, and for customizing embeddings with `Jinja2`_\nand `Mustache`_ templates.  For more information, see the `PyEmbed`_ website.\n\nCompatibility\n-------------\n\nPyEmbed has been tested with Python 2.7 and 3.3.\n\nInstallation\n------------\n\nPyEmbed can be installed using pip:\n\n::\n\n    pip install pyembed\n\nContributing\n------------\n\nTo report an issue, request an enhancement, or contribute a patch, go to\nthe PyEmbed `GitHub`_ page.\n\nLicense\n-------\n\nPyEmbed is distributed under the MIT license.\n\n::\n\n    Copyright (c) 2013 Matt Thomson\n\n    Permission is hereby granted, free of charge, to any person obtaining\n    a copy of this software and associated documentation files (the\n    \"Software\"), to deal in the Software without restriction, including\n    without limitation the rights to use, copy, modify, merge, publish,\n    distribute, sublicense, and/or sell copies of the Software, and to\n    permit persons to whom the Software is furnished to do so, subject to\n    the following conditions:\n\n    The above copyright notice and this permission notice shall be\n    included in all copies or substantial portions of the Software.\n\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n    EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n    MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n    NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\n    LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\n    OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\n    WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n.. _OEmbed: http://oembed.com\n.. _Flickr: http://flickr.com\n.. _Twitter: http://twitter.com\n.. _YouTube: http://youtube.com\n.. _Markdown: https://pypi.python.org/pypi/pyembed-markdown\n.. _reStructuredText: https://pypi.python.org/pypi/pyembed-rst\n.. _Jinja2: https://pypi.python.org/pypi/pyembed-jinja2\n.. _Mustache: https://pypi.python.org/pypi/pyembed-mustache\n.. _PyEmbed: http://pyembed.github.io\n.. _GitHub: https://github.com/pyembed/pyembed\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 75,
        "query": "This library is deprecated, please use rollbar-agent_\n=====================================================\n\nratchet-agent\n=============\nA daemon to monitor log files and push messages to Ratchet.io_.\n\n\nRequirements\n------------\nratchet-agent requires:\n\n- A unix-like system (tested on Fedora Linux and Mac OS X)\n- Python 2.6+\n- requests 0.13.1+\n- a Ratchet.io_ account\n\n\nInstallation\n------------\nInstall with pip::\n\n    pip install ratchet-agent\n\nThis will install the ratchet-agent files in the root directory of your virtualenv. Or if you'd prefer, clone this git repo:\n\n    git clone https://github.com/ratchetio/ratchet-agent.git\n\nSee Configuration for configuration options and setup.\n\nratchet-agent comes with an example init.d script, chkconfig compatible and tested on Fedora Linux. To install it, symlink ``ratchet-agent-init.sh`` to ``/etc/init.d/ratchet-agent`` and add to chkconfig::\n\n    ln -s /path/to/ratchet-agent/ratchet-agent-init.sh /etc/init.d/ratchet-agent\n    chkconfig --add ratchet-agent\n    chkconfig on ratchet-agent\n    service ratchet-agent start\n\nConfiguration\n-------------\nConfiguration options for ratchet-agent itself are in `ratchet-agent.conf`. If you're using the init script, it has a few of its own configuration variables inside which control how it runs.\n\n**ratchet-agent.conf**\nAt the bare minimum, you will want to change the following variables:\n\n- ``params.access_token`` -- your Ratchet.io access token\n- ``targets`` -- white-space-separated list of files or directories (non-recursive) to process.\n\nSetting the following variables will improve github integration:\n\n- ``params.root`` -- path to your code root\n- ``params.branch`` -- the current branch\n\nOther options are documented in the sample config file.\n\n**ratchet-agent-init.sh**\nConfiguration variables should be self-explanatory. If you're not using a virtualenv, set ``VIRTUALENV=\"\"``.\n\n\nContributing\n------------\n\nContributions are welcome. The project is hosted on github at http://github.com/ratchetio/ratchet-agent\n\n\nAdditional Help\n---------------\nIf you have any questions, feedback, etc., drop me a line at brian@ratchet.io\n\n\n.. _rollbar-agent: https://github.com/rollbar/rollbar-agent\n.. _Ratchet.io: http://ratchet.io/\n.. _`download the zip`: https://github.com/ratchetio/django_ratchet/zipball/master\n.. _ratchet-agent: http://github.com/ratchetio/ratchet-agent\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 76,
        "query": "Multilingual natural language tools, wrapping NLTK and other systems.\n\n## Deprecated as of June 2014\n\n`metanl` is no longer actively developed or supported.\n\nThis package was created to support the language-processing needs that\n[ConceptNet 5](http://conceptnet5.media.mit.edu) shared with code developed at\nLuminoso. Those needs have diverged, to the point where it made the most sense\nto split the functionality again.\n\nA simplified version of metanl has been moved into the `conceptnet5`\npackage, as `conceptnet5.language`.\n\n\n## metanl.token_utils\n\nUtilities for working with tokens:\n\n- `tokenize` splits strings into tokens, using NLTK.\n- `untokenize` rejoins tokens into a correctly-spaced string, using ad-hoc\n  rules that aim to invert what NLTK does.\n- `un_camel_case` splits a CamelCased string into tokens.\n\nThese functions make assumptions that work best in English, and work reasonably\nin other Western languages, and fail utterly in languages that don't use\nspaces.\n\n\n## metanl.nltk_morphy\n\n`nltk_morphy` is a lemmatizer (a stemmer with principles). It enables you to\nreduce words to their root form in English, using the Morphy algorithm that's\nbuilt into WordNet, together with NLTK's part of speech tagger.\n\nMorphy works best with a known part of speech. In fact, the way it works in\nNLTK is pretty bad if you don't specify the part of speech. The `nltk_morphy`\nwrapper provides:\n\n- An alignment between the POS tags that `nltk.pos_tag` outputs, and the input\n  that Morphy expects\n- A strategy for tagging words whose part of speech is unknown\n- A small list of exceptions, for cases where Morphy returns an unintuitive\n  or wrong result\n\n## metanl.extprocess\n\nSometimes, the best available NLP tools are written in some other language\nbesides Python. They may not provide a reasonable foreign function interface.\nWhat they do often provide is a command-line utility.\n\n`metanl.extprocess` provides abstractions over utilities that take in natural\nlanguage, and output a token-by-token analysis. This is used by two other\nmodules in `metanl`.\n\n### metanl.freeling\n\nFreeLing is an NLP tool that can analyze many European languages, including\nEnglish, Spanish, Italian, Portuguese, Welsh, and Russian. This module\nallows you to run FreeLing in a separate process, and use its analysis\nresults in Python.\n\n### metanl.mecab\n\nIn Japanese, NLP analyzers are particularly important, because without one\nyou don't even know where to split words.\n\nMeCab is the most commonly used analyzer for Japanese text. This module runs\nMeCab in an external process, allowing you to get its complete analysis\nresults, or just use it to tokenize or lemmatize text.\n\nAs part of MeCab's operation, it outputs the phonetic spellings of the words\nit finds, in kana. We use this to provide a wrapper function that can\nromanize any Japanese text.\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 77,
        "query": "# Deprecated Fork\nThis fork has now moved to https://bitbucket.org/6ft/django-media-manager which is maintained by the Six Foot team.\n\n# Changelog\n\n### 11-17-2014 v4.0.6\n*   Gave FileBrowseField a default max_length of 255. Can be overridden in declaration.\n*   Added a `deconstruct` method that is necessary for Django 1.7 migrations.\n\n### 11-17-2014 v4.0.5\n*   Made FileBrowseField.js more cautious about wether the \"link\" DOM object exists.\n\n### 11-13-2014 v4.0.4\n*   Bug fix. If value on a FileBrowseField is blank, it's set to '' in the database.\n\n### 11-13-2014 v4.0.3\n*   Bug fix. Field now returns None or empty string if blank.\n\n### 11-13-2014 v4.0.2\n*   Bug fix. Field should have had `self.file = None` when no file is assigned.\n\n### 11-13-2014 v4.0.1\n*   Urls are now encoded properly so they can be output anywhere.\n*   `path` property of FileObject is still unencoded to ensure the filename is still available.\n\n### 11-11-2014 v4.0.0\n*   BREAKS BACKWARDS COMPATIBILITY: Due to the default that files are stored with\n    relative filenames rather than absolute.\n*   Uploadify is deprecated; Uses qq uploader now.\n*   Still targeting Python 3 only.\n*   FileBrowseFields can now integrate with imagekit as it mimics an FileField \n    interface now.\n\n### 25-08-2014 v3.4.0\n*   Uses Pillow now.\n*   Python 3 only now.\n\n### 02-07-2013\n*\tRefactor and resolved an issue on window.opener event.\n*\tRefactor FB_Redactor plugin.\n\n### 28-06-2013\n\n*\tSupport for django-suit\n*\tSupport for django-suit-ckeditor\n*\tSupport for django-suit-redactor\n*\tSupport for custom user model\n*\tMandatory django version higher 1.5\n\n## Basic Installation\n\n\tpip install django-media-manager\n\tor\n\tpip install git+ssh://git@bitbucket.org:6ft/django-media-manager.git\n\n*\tAdd filebrowser to INSTALLED_APPS.\n*\tAdd the following line _before_ the admin URLS:\n*\t\t(r'^admin/filebrowser/', include('filebrowser.urls'))\n*\tCollect static files\n*\tAdd __uploads/__ folder to media folder or customize this setting\n\n## Suit support\nThe application have support for [django-suit](https://github.com/darklow/django-suit) template. To use it add on your settings files the following config:\n\n<code>FILEBROWSER_SUIT_TEMPLATE = True</code> \n\nFilebrowser will now use templates for django suit.\n\n## Suit CKEditor/Redactor\nTo use filebrowser on [django-suit-ckeditor](https://github.com/darklow/django-suit-ckeditor) or [django-suit-redactor](https://github.com/darklow/django-suit-redactor) please follow the example bellow:\n\n\t#models.py\n\t\n\tfrom django.db import models\n\tfrom filebrowser.fields import FileBrowseField\n\t\n\tclass MediaPublication(models.Model):\n    \tckeditor = models.TextField(help_text='Editor CKEditor')\n    \tredactor = models.TextField(help_text='Editor Redactor')\n    \timage = FileBrowseField(\"Image\", max_length=200, blank=True, null=True)\n    \timage_initialdir = FileBrowseField(\"Image (Initial Directory)\", max_length=200, directory=\"images/\", blank=True, null=True)\n    \timage_extensions = FileBrowseField(\"Image (Extensions)\", max_length=200, extensions=['.jpg'],\n                                       help_text=\"Only jpg-Images allowed.\", blank=True, null=True)\n    \timage_format = FileBrowseField(\"Image (Format)\", max_length=200, format='Image', blank=True, null=True)\n    \tpdf = FileBrowseField(\"PDF\", max_length=200, directory=\"documents/\", extensions=['.pdf'], format='Document',\n                          blank=True, null=True)\n\n    \tclass Meta:\n        \tordering = ['image',]\n        \tverbose_name = 'publication'\n        \tverbose_name_plural = 'publications'\n\nTo use on admin you need to do some litle tweeks:\n\n\t#admin.py\n\tfrom django.contrib import admin\n\tfrom django.forms import ModelForm, Media\n\tfrom suit_ckeditor.widgets import CKEditorWidget\n\tfrom suit_redactor.widgets import RedactorWidget\n\n\tfrom .models import MediaPublication\n\n\n\tclass Editor(ModelForm):\n    \tclass Meta:\n        \twidgets = {\n            \t'ckeditor': CKEditorWidget(editor_options={'startupFocus': True}),\n            \t'redactor': RedactorWidget(editor_options={\n                \t'lang': 'en',\n                \t'plugins': ['filebrowser']\n            \t}),\n        \t}\n\n    \tclass Media:\n        \tjs = ('filebrowser/js/FB_CKEditor.js', 'filebrowser/js/FB_Redactor.js')\n        \tcss = {\n            \t'all': ('filebrowser/css/suit-filebrowser.css',)\n        \t}\n        \t\n    class AdminPublication(admin.ModelAdmin):\n    \tform = Editor\n\n    \tfieldsets = (\n        \t(None, {\n            \t'classes': ('suit-tab suit-tab-media',),\n            \t'fields': ['image', 'image_initialdir', 'image_extensions', 'image_format', 'pdf'],\n        \t}),\n        \t('CKEditor', {\n            \t'classes': ('full-width',),\n            \t'fields': ('ckeditor',)\n        \t}),\n        \t('Redactor', {\n            \t'classes': ('full-width',),\n            \t'fields': ('redactor',)\n        \t}),\n    \t)\n\n    \tlist_display = ('thumbnail', 'image_extensions', 'pdf')\n    \tsuit_form_tabs = (('media', 'Media'),)\n\n    \tdef thumbnail(self, obj):\n        \tif obj.image:\n            \treturn '<img src=\"%s\" />' % obj.image.url_thumbnail\n        \telse:\n            \treturn \"\"\n    \tthumbnail.allow_tags = True\n\n\n\tadmin.site.register(MediaPublication, AdminPublication)\n   \nThe most important things are on ModelForm (Media and Widgets). To use browser on CKEditor and have the button to navigate on filebrowser you only need to add the js file to Media\n\nFor Redactor you will have to add the plugin option on the widget (plugin name is mandatory - _filebrowser_ ) and add the css and js file to media.\n\nThat's it you are now ready to send all kind of files to ckeditor or redactor.\n\n### Screenshots\n\n![](https://dl.dropboxusercontent.com/u/14340361/works/filebrowser.jpeg)\n![](https://dl.dropboxusercontent.com/u/14340361/works/filebrowser-versions.jpeg)\n![](https://dl.dropboxusercontent.com/u/14340361/works/ckeditor-browser.jpeg)\n![](https://dl.dropboxusercontent.com/u/14340361/works/ckeditor-bt-browser.jpeg)\n![](https://dl.dropboxusercontent.com/u/14340361/works/ckeditor-image.jpeg)\n![](https://dl.dropboxusercontent.com/u/14340361/works/redactor-pop-up.jpeg)\n![](https://dl.dropboxusercontent.com/u/14340361/works/redactor-import.jpeg)\n![](https://dl.dropboxusercontent.com/u/14340361/works/redactor-files-select.jpeg)\n\n#### TODO\n\nPlease this is a work in progress. If you have ideas or want to make it better please fel free to pull requests.\n\n*\tAdd more options on thumbs sizes\n\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 78,
        "query": "Deprecated\n==========\n\nThe plonesocial.* group of packages has become ploneintranet_.\n\nPlone Intranet features a complete redesign and re-implementation of the\nfront-end user interface of plonesocial. The backend is largely unchanged\nbut extended with new features: liking updates, personalized tagging.\n\nWork on the ploneintranet `code base`_ is sponsored by the\n`Plone Intranet Consortium`_, a group of companies dedicated to delivering\nthe leading open source digital workplace platform, based on Plone.\nHave a look, you'll like it. It's 100% open source.\n\n|Cosent|_\n\nPlonesocial and Plone Intranet are initiatives by Cosent_.\n\nThis repository is maintained frozen for developers who have made forks\nfor use in their own projects. If you're one of those developers and are\ninterested in upgrading to Plone Intranet, please contact Cosent_.\n\nPlease note that commits after August 2014 are part of the ploneintranet\nrewrite, before plonesocial.* got merged into ploneintranet.*.\n\n.. _ploneintranet: https://github.com/ploneintranet/ploneintranet\n.. _code base: https://github.com/ploneintranet/ploneintranet\n.. _Plone Intranet Consortium: http://ploneintranet.com\n.. _Cosent: http://cosent.nl\n.. |Cosent| image:: http://cosent.nl/images/logo-external.png \n                    :alt: Cosent\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 79,
        "query": "##########\nDEPRECATED: Opbeat CLI\n##########\n\nPlease see https://opbeat.com/docs/articles/get-started-with-release-tracking/ for a much simpler way.\n\n\n\n\n\n.. image:: https://badge.fury.io/py/opbeatcli.png\n   :target: https://pypi.python.org/pypi/opbeatcli\n\n\n.. image:: https://secure.travis-ci.org/opbeat/opbeatcli.png?branch=dev\n   :target: http://travis-ci.org/opbeat/opbeatcli\n\n\nInstallation\n============\n\nMake sure you have Git and a supported version Python installed on your system.\nThe supported Python versions are: ``2.6.x``, ``2.7.x``, ``3.3+`` and PyPy.\n\n.. code-block:: bash\n\n    $ python --version\n\n\nOpbeat CLI can then be installed using the standard Python package installation\nmethod:\n\n.. code-block:: bash\n\n    $ pip install opbeatcli\n\nIf ``pip`` is not available, you can alternatively use ``easy_install``:\n\n.. code-block:: bash\n\n    $ easy_install opbeatcli\n\nTo verify successful installation of Opbeat CLI:\n\n.. code-block:: bash\n\n    $ opbeat --version\n\n\nUsage\n=====\n\n.. code-block:: bash\n\n    $ opbeat [common options] sub-command [sub-command options]\n\n\nCommon Options\n--------------\n\nThese options are shared by all sub-commands.\n\nTo obtain these, please go to your app settings on opbeat.com:\n\n======================   ======================================================\n``--org-id, -o``         Organization ID\n``--app-id, -a``         Application ID.\n``--secret-token, -t``   Secret API authentication token.\n======================   ======================================================\n\n\nFor more information and a complete list of the available common options,\nplease see the command help:\n\n.. code-block:: bash\n\n    $ opbeat --help\n\n\nSub-Commands\n------------\n\n\n``deployment``\n~~~~~~~~~~~~~~\n\nThis command registers a deployment of an application to a machine with\nthe Opbeat API. Deployment tracking enables advanced features of the\nOpbeat platform, such as version history and the ability to relate errors\nwith particular deployments, etc. It is meant to be run from the machine\nthat is being deployed to:\n\n.. code-block:: bash\n\n    # A basic deployment registration: Run this from your application\n    # repository directory on the machine which it's been deployed to:\n    $ opbeat -o ORGANISATION_ID -a APP_ID -t SECRET_TOKEN \\\n        deployment --component path:.\n\nFor more information and examples please see\n`deployment tracking documentation <https://opbeat.com/docs/release_standard/>`_\nand the command help:\n\n.. code-block:: bash\n\n    $ opbeat deployment --help\n\n\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 80,
        "query": "django-finial\n=============\n\n[![No Maintenance Intended](http://unmaintained.tech/badge.svg)](http://unmaintained.tech/)\n\nHierarchical template overriding on a per request basis.\n\n**Deprecation Notice:** This project is no longer actively maintained, and will not be\nupdated for future Django versions. You may be interested in similar projects such as\n[django-waffle][] or [gargoyle][].\n\n[django-waffle]: https://waffle.readthedocs.io/en/latest/\n[gargoyle]: https://gargoyle.readthedocs.io/en/latest/\n\n\nDefinition\n----------\nfin\u00b7i\u00b7al  \n`/fin\u0113\u0259l/`\n*Noun*\n\n![Alt text](finial.png \"Example of a finial in architecture.\")\n\n1. A distinctive ornament at the apex of a roof, pinnacle, canopy, or\nsimilar structure.\n2. An ornament at the top, end, or corner of an object such as a post,\npiece of furniture, etc.\n\nYou might see the relation given that this project's goal is to create a\nsparse branch of templates for each override, thus \"decorating\" the\n\"top\" of your existing templates hierarchy.\n\nWhat's it for?\n--------------\n\nAny circumstance in which you wish to do A/B testing, or do dark-launches, or even\ninclude user-specified theming (although, it's a bit heavy for general purpose use),\nyou can use django-finial to do that for you. \n\nIt's especially nice when you're not able or not willing to have multiple versions\nof your software stack deployed in order to get A/B. This allows you to do all of your\nA/B testing on the same branch/checkout.\n\n\nHow it works\n------------\n\nPrincipally, Finial works at the middleware layer of the request/response cycle.\nIf request.user is logged in and said user has overrides defined, finial will rearrange \nthe order of ```STATICFILES_DIRS```, and ```TEMPLATE_DIRS``` such that their resources\nwill be loaded before the 'default' ones. \n\nThere are other features which enable you to override URL paths to views, template_tags to\nspecify URLS for certain assets in your templates, and helpers that will build the URLConf\nsettings necessary to host static assets locally for all of your overrides.\n\nHow to install it\n-----------------\n\nInstallation is easy to get started, but can be quite customized.\n\nFor basic use:\n\n* Install the package ```(virtualenv)# pip install django-finial```\n* Add ```finial``` to your list of INSTALLED_APPS in ```settings.py```\n* Add ```finial.middleware.TemplateOverrideMiddleware``` to your project's middleware tuple\n(someplace after Session and Authentication)\n* Add ```finial.context_processors.asset_url``` to your ```TEMPLATE_CONTEXT_PROCESSORS``` tuple.\n* Run ```python manage.py migrate``` to pick up migrations and table creations\n\nThis allows you to override template loading. But it only gets you so far -- you may need\nto have an override-prefix for finial to use to find your tempalte directories.\n\nPut this in your ```settings.py``` to have finial look in ```/path/to/django/overrides/<override_name>_templates/```\n\n```python\nFINIAL_TEMPLATE_DIR_PREFIX = '/overrides' # This is the directory prefix from your PROJECT_PATH\n```\nSee ```example_settings.py``` for other common settings\n\n\nGetting Started\n---------------\n\nThere are three different systems at work in Finial: \n\n 1. Template Overrides -- short circuit template loader to load your overridden template first.\n 2. URLConf Overrides -- create a request.urlconf which puts the override url patterns first.\n 3. Staticfiles Overrides -- short circuit staticfiles loaders to load contents from override dirs.\n\n**Template Overrides**\n\nThese are the most straight forward of the three mechanisms. Basically, it takes advantage of the fact that django\nwill return the first template whose name matches the one requested by a view's response constructor. It does this\nby shuffling the order of the ```TEMPLATE_DIRS``` in settings on a per request basis in Finial's ``middleware``. Finial will\nlook for users who have overrides enabled; when it finds them it takes all of the overrides for the given user and \nrearranges the directory structure for ```TEMPLATE_DIRS``` in override priority order.\n\nPriority, in our case, assumes that lower is more important. So an override with a priority of 1 should always win out.\n\n**URLConf Overrides**\n\nThese are a little more complex, but you can opt to use these when you need to have fundamental changes to view logic\nfor a given url endpoint. It allows you to (again on a per request basis) shuffle the ordering of urlpatterns so \nan overridden view can be used in place of the default view for a given url pattern. \n\nWe do this using the django machinery which checks each request object for a ```request.urlconf``` attribute. If it finds\nthis, then it ignores the root URLConf.\n\nFinial knows to setup this request.urlconf by looking at your override urlconf module (has to be its own module) path in\n```settings.py```. We look for a dictionary of override names to urlconf import strings like the following:\n\n```python\n\nFINIAL_URL_OVERRIDES = {\n    'my_override': 'my_project.my_override_finial_patterns'\n}\n```\n\n**Staticfiles Overrides**\n\nOddly, this is the most complex of the three situations. While traditional HTTP servers were designed only with static\ncontents in mind -- django's highly dynamic nature puts it at odds with static media.\n\nWe have two areas in which we have to do pretty radically different things. In development, we need django so serve\nour content. In production we generally have static media hosted by a different domain entirely (S3, CDNs, etc.). To\naddress these differences we have a couple of helper methods to sort things out:\n\n**Local Development with Staticfiles Overrides**\n\nIn this situation people often setup custom django url endpoints to serve the static media from a checkout of their\nproject locally.\n\n```python\nif settings.DEBUG:\n    urlpatterns += patterns('',\n            url(r'^static/(?P<path>.*)$', 'django.views.static.serve', {\n                'document_root': settings.MEDIA_ROOT}),\n    )\n```\n\nSo, to get do the same for all of the overrides we're testing locally, we need a separate url endpoint for each one:\n\n```python\n\nif settings.DEBUG:\n    # Remember to do this BEFORE regular staticfiles serving.\n    urlpatterns = finial_shortcuts.create_local_override_urls(urlpatterns)\n    urlpatterns += patterns('',\n            url(r'^static/(?P<path>.*)$', 'django.views.static.serve', {\n                'document_root': settings.MEDIA_ROOT}),\n    )\n```\nYou'll notice that a lot of whether you're developing locally or working in production is determined by the ```settings.DEBUG``` flag.\nIf you use some other variable for this, make sure that it mimics DEBUG.\n\nHowever, there's still one more thing you must do to get your static media to load properly for local development.\nMake sure to prepend your ```settings.STATICFILES_FINDERS``` with ```finial.finders.FinialFileSystemFinder```.\n\nYour ```local_settings.py``` should look something like this for staticfiles configurations:\n\n```python\n\nDEBUG=True\nPROJECT_PATH = '/path/to/django/root/'\nFINIAL_URL_VERSION_PREFIX = 'deploy5-'\nFINIAL_STATIC_URL_PREFIX = 'https://s3.amazonaws.com/com.finial.media'\nFINIAL_TEMPLATE_DIR_PREFIX = '/overrides'\nSTATICFILES_FINDERS = (\n    'finial.finders.FinialFileSystemFinder',\n    'django.contrib.staticfiles.finders.FileSystemFinder',\n    'django.contrib.staticfiles.finders.AppDirectoriesFinder',\n)\n```\n\n_Note_: If we want to not require all of our overrides directories to live in our project root, we need to specify\na ```FINIAL_TEMPLATE_DIR_PREFIX``` which is applied after the ```PROJECT_PATH``` variable. The 'root' override directory\nfrom the example above would be ```/path/to/django/root/overrides/```.\n\n\n**Production with Staticfiles Overrides**\n\nAgain, we know we're in production based on the ```settings.DEBUG``` value being ```False```. In that case instead of using local paths,\nwe construct a URL using ```settings.FINIAL_STATIC_URL_PREFIX```, the override name, and optionally a deploy version (\nspecified with ```settings.FINIAL_URL_VERSION_PREFIX```\n\nThe URLs for these assets are determined by the template context processor that we installed in our ```settings.TEMPLATE_CONTEXT_PROCESSORS```\nback in the begining.\n\n\n**Directory Structure**\n\nSince templates and staticfiles are so totally different, we keep them in separate directory structures.\n\n```\n~/path/to/django/overrides/$ tree\n.\n\u251c\u2500\u2500 test_or_staticfiles\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 images\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 configure-image.png\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 docs-image.png\n\u2514\u2500\u2500 test_or_template\n    \u251c\u2500\u2500 apps\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 view.html\n    \u2514\u2500\u2500 base.html\n\n4 directories, 4 files\n```\n\nOr, alternatively, you can actually put your static media in a 'chroot' inside the test of your static media\nby defining the ``FINIAL_URL_PREFIX``:\n\nIn settings.py:\n```python\nFINIAL_STATIC_URL = 'static/'\nFINIAL_URL_PREFIX = 'overrides/'\n```\nThen you could have a directory structure like so:\n```\n~/path/to/django/static$ tree\nstatic/\n\u2514\u2500\u2500 overrides\n    \u2514\u2500\u2500 test_or\n        \u2514\u2500\u2500 apps\n            \u251c\u2500\u2500 configure-image.png\n            \u2514\u2500\u2500 docs-image.png\n\n3 directories, 2 files\n```\n\nThis is particularly nice because it enables us to differentiate between overrides on the same CDN.\nWe don't need to deploy to separate S3 buckets for each override.\n\nCreating/Assigning Overrides\n----------------------------\n**Simple Override Creation**\nThe easy, straightforward way is to simply enter form fields using the Admin interface.\nThis works great for adding singular individuals, or for getting a test override setup in\nyour development environment.\n\n\nBasically, each row in the overrides table defines four things:\n\n- Who\n- Name of the overrides (used in things like urlconf keynames, etc.)\n- Directory path of the overrides (may be used in conjunction with `FINIAL_TEMPLATE_DIR_PREFIX`).\n- Priority (how should this override be rated vs. others?)\n\n**Programmatic Override Creation**\n\nThis is mostly filesystem stuff and some configs. If you've completed the settings assignments above, then\nwe're one step closer.\n\nTaking our ``FINIAL_TEMPLATE_DIR_PREFIX`` into account, we can create a structure like this:\n\n```bash\nmdkir $PROJECT_ROOT/overrides/test_override_template\n```\n\nNow you can copy the specific templates over that you'd like to change. These should be picked up before \n\"regular\" templates for those users who have the override.\n\n**Assigning the Override to a User**\n\nInside your ``manage.py shell``:\n\n```python\n\n>>> from finial import models\n>>> from django.contrib.auth.models import User\n>>> me = User.objects.get(username='gavin') # whichever username here.\n>>> my_override = models.UserTemplateOverride()\n>>> my_override.user = me\n>>> my_override.priority = 10 # In case there are more overrides later\n>>> # These two are always the same in our system; we may do away with one someday...\n>>> my_override.override_name = 'test_override'\n>>> my_override.override_dir = 'test_override'\n>>> my_override.save()\n```\n\nNow login as this user, ``gavin`` in this case, and see if the templates loaded for this user are different\nas you expect.\n\n\nProducing Results: Context Processors\n-------------------------------------\n\nThere are two primary ways of surfacing the differences within template data to users. Both of these make use of\nDjango's Context Processors. As such, you'll need to make sure that views you're attempting to override\nprovide the template with a ``RequestContext`` context type (the default for ```http.render()`` now).\n\n\n**Changing Your Media URLs with asset_url**\n\nIf you just need to modify the ``MEDIA_URL`` or ``STATIC_URL``, then you'll want to use the ``asset_url``.\n\nThe ``asset_url`` assumes you have a request context (because there's data we tack onto the request object\nabout which override we're selecting). You'll use this method in situations in which the static media\nlinked to in the template are different than they are for the rest of the site. It works in two parts;\nfirst, you'll need to define which override is \"active\" for a given view using a decorator; \nsecond, you'll need to make sure that the ``asset_url`` context processor is setup (only needs to happen once).\nUsually, this is necessary when you're doing ``URLConf`` overrides.\n\nIn Settings.py:\n```python\n\nfrom django.conf.global_settings import TEMPLATE_CONTEXT_PROCESSORS\n\nTEMPLATE_CONTEXT_PROCESSORS += (\n  'finial.context_processors.asset_url'\n)\n```\n\nIn your view:\n```python\n\nfrom finial.decorators import active_override\n\n@active_override('test_or')\ndef override_view(request, *args, **kwargs):\n   # Sometimes it's easiest just to proxy back to the original view.\n   return original_view(request, *args, **kwargs)\n\n```\n\nNow the template returned by ``original_view`` will automatically have their\n``MEDIA_URL``, and ``STATIC_URL`` converted to the appropriate URL for \nlocal development, or for production (as defined by ``settings.DEBUG``).\n\n\n**Informing Javascript of Overrides with override_names**\n\nSometimes your Javascript code will be pretty divorced from your Django deployment. In those cases,\nyou cannot rely on Finial to do the right thing. Instead finial comes with the ability to just inform\nJavascript code of which overrides are present for a given user. For this we use the ``override_names``\ncontext processor.\n\nConsider the following template code (note: this is mean to always be rendered for a site, not just in an override).\n\n```html\n{% if FINIAL_POINTS %}\n <div id=\"finial\" data-set=\"{{ FINIAL_POINTS }}\"></div>\n{% endif %}\n```\n\nThis way, javascript gets a string which it can parse using a JSON parser to get a list of override_names (in priority order),\nand can make the appropriate choices with which functions to include/run, or templates to render.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 81,
        "query": ".. contents::\n\n.. warning::\n   This recipe has been deprecated in favor of `djc.recipe2`_.\n   If you are starting a new project,\n   **don't use this package**,\n   use `djc.recipe2`_.\n   This package might see minor bug fixes to keep existing buildouts running,\n   but it won't gain new features.\n\nThis recipe allows you to setup a Django_ project through `zc.buildout`_.\n\nUsage\n*****\n\nThe main scope of the recipe is to abstract out the ``settings.py`` file,\nallowing settings to reside inside the buildout instead of having them reside\ninto code (leading to an awkard handling of the same in respect to versioning,\nfor example). The ``settings.py`` file is generated by a template, either the\ndefault one, the default one and a user extension, or a totally new one.\n\nThe template uses the Tempita_ templating system.\n\nThe most basic usage of this recipe is as follows: ::\n\n    [buildout]\n    parts = django\n\n    [django]\n    recipe = djc.recipe\n    project = my.project\n\nWhere ``my.project`` is an importable package containing a ``urls`` module and\na ``templates`` directory.\n\nAs you see, very few options are specified here: the defaults are used to build\nup the ``settings.py`` file.\n\nOf course, real examples tend to be slightly more complex: see Options_,\n`Default template options`_ and `Example usage`_ for more details.\n\nRunning tests\n*************\n\nThe ``README.txt`` located within the package also acts as main doctest.\n\nTo run the tests, check out the source, and then bootstrap and run the buildout::\n\n    $ python bootstrap.py\n    $ bin/buildout\n\nThen you can run the tests using::\n\n    $ bin/test\n\nLinks\n*****\n\n- Code repository: http://github.com/abstract-open-solutions/djc.recipe\n- Discussions at https://groups.google.com/group/djcrecipe\n- Comments and questions at info@abstract.it\n\n.. _Django: http://www.djangoproject.com/\n.. _`zc.buildout`: http://www.buildout.org/\n.. _Satchmo: http://www.satchmoproject.com\n.. _`djc.recipe2`: http://pypi.python.org/pypi/djc.recipe2\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 82,
        "query": "DEPRECATED!\n===========\nThis work has been merged upstream into `pyzmq <https://github.com/zeromq/pyzmq>`_\n----------------------------------------------------------------------------------\n\n=============\ngevent-zeromq\n=============\n\nThis library wraps pyzmq to make it compatible with gevent. \u00d8MQ socket\noperations that would normally block the current thread will only block the\ncurrent greenlet instead.\n\nRequirements\n------------\n\n* pyzmq==2.2.0\n* gevent (compatible with 1.0 pre-releases as well)\n\n\nUsage\n-----\n\nInstead of importing zmq directly, do so in the following manner:\n\n..\n    \n    from gevent_zeromq import zmq\n\n\nAny calls that would have blocked the current thread will now only block the\ncurrent green thread.\n\n\nAbout\n-----\n\nThis compatibility is accomplished by ensuring the nonblocking flag is set\nbefore any blocking operation and the \u00d8MQ file descriptor is polled internally\nto trigger needed events.\n\nWill build with cython if available, decreasing overhead.\n\nLicense\n-------\nSee LICENSE (New BSD)\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 83,
        "query": "===========\nDeprecated\n===========\nPlease use https://github.com/iMerica/dj-rest-auth as this project is no longer maintained. Thanks!\n\n\nWelcome to django-rest-auth\n===========================\n\n.. image:: https://travis-ci.org/Tivix/django-rest-auth.svg\n    :target: https://travis-ci.org/Tivix/django-rest-auth\n\n\n.. image:: https://coveralls.io/repos/Tivix/django-rest-auth/badge.svg\n    :target: https://coveralls.io/r/Tivix/django-rest-auth?branch=master\n\n\n.. image:: https://readthedocs.org/projects/django-rest-auth/badge/?version=latest\n    :target: https://readthedocs.org/projects/django-rest-auth/?badge=latest\n\n\nDjango-rest-auth provides a set of REST API endpoints for Authentication and Registration\n\n\nDocumentation\n-------------\nhttp://django-rest-auth.readthedocs.org/en/latest/\n\n\nSource code\n-----------\nhttps://github.com/Tivix/django-rest-auth\n\n\nStack Overflow\n-----------\nhttp://stackoverflow.com/questions/tagged/django-rest-auth\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 84,
        "query": "## Deprecation notice\n\n\nThis repository has been deprecated in favour of language specific repositories below. \n\n[cloudformation-custom-reousrces-nodejs](https://github.com/base2Services/cloudformation-custom-resources-nodejs) \nand\n[cloudformation-custom-reousrces-python](https://github.com/base2services/cloudformation-custom-resources-python)\n \nPlease refer to these repositories for any further details. \nThis repository will remain present for legacy reasons. \n\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 85,
        "query": "========\nCovid-19\n========\n\n.. image:: https://gitlab.com/pydemic/covid-19/badges/master/pipeline.svg\n   :target: https://github.com/pydemic/covid-19/commits/master\n\n.. image:: https://gitlab.com/pydemic/covid-19/badges/master/coverage.svg\n   :target: https://github.com/pydemic/covid-19/commits/master\n\n\n\nThis is a Python library that simulates COVID-19 outbreaks. The main focus is on Brazil, but it\nincludes demographic data about other countries and can be adapted with relative ease. This library\nimplements the RSEICHA model (yet to be published, we will link the preprint here). One version,\n`covid.models.RSEICHADemografic` considers demographic information and the other, `covid.models.RSEICHA`\njust uses generic compartments.\n\n**WARNING!**\n\nThis library is deprecated and will be replaced by several projects in the Pydemic organization. If you\nwant to use the library or contribute to its development, please contact the developers first.\n\n\nUsage\n=====\n\nYou can run models from the command line::\n\n$ python -m covid.models.seichar\n\nOr, more typically, from Python code\n\n>>> from covid.models import SEICHAR\n>>> m = SEICHAR(region='Italy')\n>>> run = m.run()\n>>> run.plot()\n>>> print(run)\n\nCalculator\n----------\n\nTo serve the app calculator, use::\n\n    $ inv run\n\nInstallation\n============\n\nEither clone this repository and install locally using `flit install -s` or use\n`pip install covid-models`. If you do not have flit, install it using either your distribution\npackage manager or use `pip install flit --user`.\n\nThe model\n=========\n\nSEICHAR is a compartmental model with 8 compartments: Recovered, Fatalities, Susceptible, Exposed,\nInfectious, Critical (require ICU care), Hospitalized (or requires hospitalization) and Asymptomatic.\n\nIt is governed by the following dynamics:\n\nBasic theoretical results\n-------------------------\n\nIf we ignore the \"Exposed\" compartment, it is easy to derive R0 for this model. We must, however,\nconsider the number of equivalent infectious :math:`I_e = I + \\mu A`, in which asymptomatic individuals\ncontribute less to the overall number of infectious than symptomatic cases.\n\nWhen :math:`S \\simeq N`, this quantity experience an exponential growth and we can associate R0 with\n:math:`R_0 = \\frac{\\beta}{\\gamma}\\left[1 - (1 - \\mu) p_s\\right]`\n\nDefault parameters\n------------------\n\n+------------------+----------------------+------------------------------------+\n| Parameter        | Default value        | Reference                          |\n+==================+======================+====================================+\n|                  |                      |                                    |\n+------------------+----------------------+------------------------------------+\n\nParameters and references\n=========================\n\nEpidemiological parameters\n--------------------------\n\nClinical parameters\n-------------------\n\nRequired medical resources\n--------------------------\n\nDevelopment\n===========\n\nTesting\n-------\n\nSimply perform::\n\n    $ inv test\n\nManaging i18n\n-------------\n\nTo update messages files::\n\n    $ inv makemessages\n\nTo compile messages files::\n\n    $ inv compilemessages\n\nTo update and compile messages files::\n\n    $ inv i18n\n\nUsing rit tunnel\n----------------\n\nAfter installing `rit <https://gitlab.com/ritproject/cli#installation>`_, config your tunnel repo:\n\n- Remotely::\n\n  $ rit config tunnel add repo https://gitlab.com/pydemic/tunnel --name pydemic\n  $ rit config tunnel default set pydemic --path .\n\n- Locally::\n\n  $ git clone https://gitlab.com/pydemic/tunnel ../tunnel\n  $ rit config tunnel add local ../tunnel --name pydemic\n  $ rit config tunnel default set pydemic --path .\n\nExamples of usage:\n\n- If you use docker and docker-compose, you can:\n\n  - Build the development image::\n\n    $ rit tunnel run apps calculator development build\n\n  - Fetch the development docker-compose::\n\n    $ rit tunnel run apps calculator development fetch compose\n\n  - Run the test pipeline::\n\n    $ rit tunnel run apps calculator development test up\n    $ rit tunnel run apps calculator development test sync\n    $ rit tunnel run apps calculator development test all\n    $ rit tunnel run apps calculator development test down\n\n  - Build the production image::\n\n    $ rit tunnel run apps calculator production build\n\n  - Fetch the production docker-compose::\n\n    $ rit tunnel run apps calculator production fetch compose\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 86,
        "query": "[This is deprecated software. I recommend using MetaBAT or one of the other fully developed binning methods.]\n\n# Distribution-based Binner (DBB)\n\nCluster scaffolds from a single metagenomic sample into population genomes using a distribution-based binning approach.\n\n\n## Install\n\nThe simplest way to install this package is through pip:\n> sudo pip install dbb\n\nDBB relies on numpy, scipy, matplotlib, and pysam v0.7.x. \n\n## Cite\n\nIf you find this package useful, please cite this git repository (https://github.com/dparks1134/dbb)\n\n## Copyright\n\nCopyright \u00a9 2015 Donovan Parks. See LICENSE for further details.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 87,
        "query": "# WE'VE MOVED\n\n### [This repository is now being hosted on GitLab's servers.](https://gitlab.com/brohrer/cottonwood)\nCheck it out at [https://gitlab.com/brohrer/cottonwood](https://gitlab.com/brohrer/cottonwood).\nInstall from there. Update from there.\n\nTo make the switch on your local machine command line run\n\ngit remote set-url origin https://gitlab.com/brohrer/cottonwood.git\n\nor\n\ngit remote set-url origin git@gitlab.com:brohrer/cottonwood.git\n\ndepending on which protocol you're using.\n\nThis repo is being deprecated and will no longer be updated. BTW GitLab is pretty intuitive if you're already familiar with GitHub. [Check it out.](https://gitlab.com/)\n\n--\n\n--\n\n--\n\n--\n\n# The Cottonwood Machine Learning Framework\n\nCottonwood is built to be as flexible as possible, top to bottom.\nIt's designed to minimize the iteration time when running experiments\nand testing ideas. It's meant to be tweaked. Fork it. Add to it. Customize it\nto solve the problem at hand. For more of the thought behind it, read\nthe post \"\n[Why another framework?](https://end-to-end-machine-learning.teachable.com/blog/171633/cottonwood-flexible-neural-network-framework)\nand\n[Why did you name it that?](https://end-to-end-machine-learning.teachable.com/blog/193739/why-is-it-called-cottonwood)\n\nThis code is always evolving. I recommend referencing a specific tag\nwhenever you use it in a project. Tags are labeled v1, v2, etc. and\nthe code attached to each one won't change.\n\nIf you want to follow along with the construction process for Cottonwood,\nyou can get a step-by-step walkthrough in the e2eML sequence\n[Course 312](https://end-to-end-machine-learning.teachable.com/p/write-a-neural-network-framework/),\n[Course 313](https://end-to-end-machine-learning.teachable.com/p/advanced-neural-network-methods/),\nand\n[Course 314](https://end-to-end-machine-learning.teachable.com/p/314-neural-network-optimization/).\n\n## Installation\n\nWhether you want to pull Cottonwood into another project, \nor experiment with ideas of your own, you'll want\nto clone the repository to your local machine and install it from there.\n\n```bash\ngit clone https://github.com/brohrer/cottonwood.git\npython3 -m pip install -e cottonwood\n```\n\n## Try it out\n\n```bash\npython3\n```\n```python3\n>>> import cottonwood.demo\n```\n\nHere is\n[the cheatsheet for pulling the relevant components](cottonwood/doc/cheatsheet.md)\ninto your work.\n\n## Versioning\n\nCottonwood versions are **not** guaranteed backward compatible.\nYou can select a particular version to work from.\n\n```\ncd cottonwood\ngit checkout v14\n```\n\n## Examples\n\nSee what Cottonwood looks like in action.\nFeel free to use any of these as a template for a project of your own.\nThey're MIT licensed.\n\n* [Compress images of the surface of Mars](\n  https://github.com/brohrer/cottonwood_martian_images)\n\n## Contribute to the project\n\n[Here are some ideas to get you started.](cottonwood/doc/contributing.md)\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 88,
        "query": "\n**Status: UNMAINTAINED**\n\nContact me if you want to take the lead.\n\n\n\n\ndj-revproxy\n-----------\n\nDjango reverse proxy. Allows you to proxy any website behind a prefix.\n\nRequirements\n------------\n\n- `Python <http://www.python.org>`_ 2.x superior to 2.5 and Django\n- `Django <http://www.djangoproject.org>`_  >= 1.2\n- `restkit <http://benoitc.github.com/restkit>`_ >= 2.3.2\n\nInstallation\n------------\n\nInstall from sources::\n\n  $ python setup.py install\n\nOr from Pypi::\n\n  $ easy_install -U dj-revproxy \n\nConfiguration\n-------------\n\nAdd `revproxy`  to the list of applications::\n\n    INSTALLED_APPS = (\n        ...\n        'revproxy'\n    )\n\nUsage\n-----\n\nSince 0.2, there is 2 ways to use dj-revproxy.\n\n\n1. Generic view\n+++++++++++++++\n\nYou can use ``proxy_request`` function to proxy any url. You can use it in your code::\n\n    proxy_request(request, \"http://example.com\")\n\nThis code will proxy current request to ``http://example.com`` domain.\nThis function can take 5 parameters:\n\n- destination: string, the proxied url. Required\n- path: string, If no path is given it will try to detect the url using\n  the prefix if it's given. If not full request.path will be used in\n  finl destination url.\n- prefix: string, the prrefix behind we proxy the path\n  headers: dict, custom HTTP headers\n- no_redirect: boolean, False by default, do not redirect to \"/\" \n  if no path is given\n- decompress: boolean, False by default. If true the proxy will\n  decompress the source body if it's gzip encoded.\n\nIt return an instance of ``django.http.HttpResponse``. You can use it  directly\nin your urls.py (which is the eaiest way to use). Ex::\n\n    (r'^gunicorn(?P<path>.*)', \"revproxy.proxy.proxy_request\", {\n        \"destination\": \"http://gunicorn.org\"\n    }),\n\n2. Configure multiple proxy behind one generic prefix\n+++++++++++++++++++++++++++++++++++++++++++++++++++++\n\nTo configure a proxy add a tupple to the REVPROXY_SETTINGS list::\n\n    REVPROXY_SETTINGS = [\n        (\"_google\", \"http://google.com\"),\n        (\"_friendpaste\", \"http://www.friendpaste.com\"),\n        (\"_couchdb\", \"http://127.0.0.1:5984\"),\n    ]\n\nThen configure your proxied urls automatically do something like this in\n``urls.py``:: \n    from django.conf.urls.defaults import *\n\n    import revproxy.proxy\n\n    urlpatterns = patterns('',\n        ...\n        (r'^proxy/', include(proxy.site_proxy.urls)),\n    )\n\nWhich will allow you to proxy Google on the url::\n\n    http://127.0.0.1:8000/proxy/_google\n\nor even::\n\n    ('^proxy/(?P<prefix>[^\\/]*)(.*)', \"proxy.site_proxy\"),\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 89,
        "query": "**NOTE: This repository is now mostly in archive.** Please head over to the `Mathics3 mathics-core github repository <https://github.com/Mathics3/mathics-core>`_.\n\nWelcome to Mathics!\n===================\n\n|Pypi Installs| |Latest Version| |Supported Python Versions| |Travis|_ |SlackStatus|_\n\n|Packaging status|\n\n\nMathics is a general-purpose computer algebra system (CAS). It is an open-source alternative to Mathematica. It is free both as in \"free beer\" and as in \"freedom\".\n\nThe home page of Mathics is https://mathics.org.\n\n\nScreenShots\n-----------\n\nmathicsscript: a text interface\n+++++++++++++++++++++++++++++++\n\n|mathicsscript|\n\nmathicsserver: a Django-based Web interface\n+++++++++++++++++++++++++++++++++++++++++++\n\n|mathicssserver|\n\n\nInstalling and Running\n----------------------\n\nSee the `read the docs guide <https://mathics-development-guide.readthedocs.io/en/latest/>`_ for instructions on `installing <https://mathics-development-guide.readthedocs.io/en/latest/installing.html>`_ and `running <https://mathics-development-guide.readthedocs.io/en/latest/running.html>`_.\n\nContributing\n------------\n\nPlease feel encouraged to contribute to Mathics! Create your own fork, make the desired changes, commit, and make a pull request.\n\n\nLicense\n-------\n\nMathics is released under the GNU General Public License Version 3 (GPL3).\n\n.. |SlackStatus| image:: https://mathics-slackin.herokuapp.com/badge.svg\n.. _SlackStatus: https://mathics-slackin.herokuapp.com/\n.. |Travis| image:: https://secure.travis-ci.org/mathics/Mathics.svg?branch=master\n.. _Travis: https://travis-ci.org/mathics/Mathics\n.. _PyPI: https://pypi.org/project/Mathics/\n.. |mathicsscript| image:: https://github.com/Mathics3/mathicsscript/blob/master/screenshots/mathicsscript1.gif\n.. |mathicssserver| image:: https://mathics.org/images/mathicsserver.png\n.. |Latest Version| image:: https://badge.fury.io/py/Mathics3.svg\n\t\t :target: https://badge.fury.io/py/Mathics3\n.. |Pypi Installs| image:: https://pepy.tech/badge/Mathics3\n.. |Supported Python Versions| image:: https://img.shields.io/pypi/pyversions/Mathics3.svg\n.. |Packaging status| image:: https://repology.org/badge/vertical-allrepos/mathics.svg\n\t\t\t    :target: https://repology.org/project/mathics/versions\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 90,
        "query": ".. contents::\n\nDEPRECATED\n==========\n\nUse `collective.factorymenu`_ on modern Plone.\n\nSummary\n=======\n\nThis product make possible the customization of the Plone \"*Add new...*\" menu, commonly filled\nfrom the Plone available content types.\n\nThis is designed for avoiding useless content types but, at the same time, help UI experience of\nnon-technical users.\n\nYou can use this to add new non-standard stuff to the menu (like JavaScript links). See below.\n\nIdea behind this\n================\n\nThe case is related to developed content types that gets added to Plone only for *usability* enhancements.\n\nOne example: have you ever used Plone4ArtistsVideo, or `collective.flowplayer`__?\nIn those products users that want to add new video to a site must use the \"*Add new...*\" menu and select\nthe *File* content.\n\n__ http://pypi.python.org/pypi/collective.flowplayer\n\nSo the editor (that is *never* a developer in real life... you must accept it) must know that when he add\na new file, it magically became a video... This is not so simple to understand; also is impossible to\nunderstand it without a training or by past experience.\nCan't be better if the user could read \"*Add new video*\" in the menu instead?\n\nRight now the best usability choice is to add a new content type to the menu, or develop a new helper portlet\nthat show some links like \"*add a new video here*\".\n\nIn the first case, just copy/paste the original used content if enough (copy/paste the *File* content type and\nrename it in something like \"Video\").\nBut you know... we don't really need those new content types.\n\nIn the second case all is ok, but what Plone users know is to look at the right menu to search for addable\ntypes, not to look in a menu and *also* in another place.\n\nSo:\n\n* user know that for adding new content types, they must use the \"*Add new...*\"\n* users often ignores the magic behind Plone (like the File that became a Video)\n* developer don't like to add new silly content types only to help end users (no, the are not bad guys).\n\nThe problem above is related to the not-customizable state of the \"Add new...\" menu: the editor and the\ndeveloper will be both happy if a new, fake entry could be added to this menu.\nGoing back to the video example:\n\n* the classic *File* entry (that point to *http://myhost/mysite/createObject?type_name=File*)\n* a new \"Video\" entry (again pointing to *http://myhost/mysite/createObject?type_name=File*)\n\nThis products is designed only for this or similar usability issues, however can help you to customize\nexisting elements of the menu on context (for example: the action of adding a new \"News Item\" content in\na folder can be customized to be an alias for another content type, but only for this special folder,\nor you can disable with a falsy espression a content type in a folder, ...).\n\nHow to use\n==========\n\nInstallation\n------------\n\nSimply add the egg to your buildout, and re-run it.\n\n::\n\n    [instance]\n    ...\n    eggs =\n        ...\n        redturtle.custommenu.factories\n    ...\n\nRemember to add also the ZCML slug and overrides if you are testing this on Plone 3.2 or lesser.\n\nAfter this, install the new product in Plone.\n\nCustomize the menu\n------------------\n\nIn your \"Add new...\" menu you'll find a new \"*Customize menu...*\" entry. This will lead you to a\nform where you must enable customization feature on the current context.\nAfter this you can use the a customization form where you can manage local menu changes.\n\n.. figure:: http://keul.it/images/plone/redturtle.customizemenu.factories1.png\n   :align: left\n\nFor every new entry you can/must fill this informations:\n\n`id`\n    Enter here a string to be used to add an HTML id attribute to the new element. You can not provide\n    it, but if you use an already existing ids, the new one will override the old.\n    In this way you can *replace* one of the native (or inherited) menu entry with a new ones.\n`name`\n    Required.\n    Provide the string to be used for displaying the new element.\n`description`\n    The description is used to provide a tooltips hovering the element.\n`icon`\n    A TALES expression that can be used to give an icon to the new element (very common).\n`condition`\n    A TALES condition expression. If not provided, the new element is added to the menu. In provided\n    it is evaluated as True or False, so the element is displayed or not.\n`URL`\n    Required.\n    A TALES expression used to render the HREF attribute on the link in the element. You have total freedom\n    here: you can also render a string as \"*javascript:...*\" to provide some Javascript features.\n\nAlso you can inherit the customization done in the site root everywhere in the site, adding this to all\nother customizations. You can also locally block the inherit of root customization but you can also make\nnew menu elements defined in the root available only in the root itself.\n\nAlso, you can give a right *id* to new entries not only to override menu element from Plone normal\nbehaviour, but also for change a customization done in the site root.\n\n.. figure:: http://keul.it/images/plone/redturtle.customizemenu.factories2.png\n   :align: left\n\nTALES expressions\n-----------------\n\nIn the TALES expression above, you can use those variables:\n\n `context`\n     The current context, as Plone normal meaning\n `container`\n     The container of the current context, or the context itself if the context is a container. This is\n     useful when writing expression that keep in mind the default document in a folder.\n `portal_url`\n     The *portal_url* tool, taken from the Plone site.\n\nGeneric setup support\n---------------------\n\nJuan. [nueces] provided Generic Setup support for this package:\n\n.. code:: xml\n\n    <?xml version=\"1.0\"?>\n    <object>\n      <property name=\"inherit\">True</property>\n      <custommenu>\n        <property name=\"element-id\">pdf-file</property>\n        <property name=\"element-name\">PDF Document</property>\n        <property name=\"element-descr\">A file content to be filled with a PDF document</property>\n        <property name=\"icon-tales\">string:$portal_url/pdf_icon.gif</property>\n        <property name=\"condition-tales\"></property>\n        <property name=\"element-tales\">string:${container/absolute_url}/createObject?type_name=File</property>\n      </custommenu>\n      <custommenu>\n          ...\n      </custommenu>\n      <object name=\"documents\">\n        <property name=\"inherit\">True</property>\n        <custommenu>\n            ...\n        </custommenu>\n        <object name=\"ebooks\">\n           <property name=\"inherit\">True</property>\n           <custommenu>\n                ...\n           </custommenu>\n           ...\n        </object>\n        ...\n      </object>\n      ...\n    <object>\n\nFor a complete code check `collective.examples.custommenufactories`__.\n\n__ http://svn.plone.org/svn/collective/collective.examples.custommenufactories/trunk/\n\nDependencies\n============\n\nAll Plone versions from 3.3 to 4.3 has been tested.\n\nTODO\n====\n\n* JavaScript features for managing entries\n* code needs refactoring\n* think about inherit customizations not only from portal root\n* subsites testing needed\n\n.. _collective.factorymenu: https://github.com/collective/collective.factorymenu\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 91,
        "query": "SMBL - SnakeMake Bioinformatics Library\n=======================================\n\n.. image:: https://travis-ci.org/karel-brinda/smbl.svg?branch=master\n\t:target: https://travis-ci.org/karel-brinda/smbl\n\n.. image:: https://travis-ci.org/karel-brinda/smbl.svg?branch=devel\n\t:target: https://travis-ci.org/karel-brinda/smbl\n\n\n**SMBL is deprecated and is not maintained any more. We recommend to replace it by BioConda (see https://bioconda.github.io).**\n\n\nShort description\n-----------------\n\n**SMBL** is a library of some useful rules and Python functions which can be used in Snakemake (https://bitbucket.org/johanneskoester/snakemake/) pipelines. It makes possible to automatically\ninstall various bioinformatics programs like read mappers, read simulators, conversion tools, etc.\nIt supports also downloading and conversion of some important references in FASTA format (e.g., human genome).\n\n\nInstallation / upgrade\n----------------------\n\nTo install SMBL, you need to have Unix-like operating system (e.g., Linux, MacOS) and Python at least 3.3.\nInstallation / upgrade can be performed using the following command.\n\n.. code-block:: bash\n\n\tpip3 install --upgrade smbl\n\n\nIf SnakeMake has not been installed, yet, it will\nbe installed automatically with SMBL.\n\nThe current version of SMBL from git can be installed by\n\n.. code-block:: bash\n\n\tpip3 install --upgrade git+git://github.com/karel-brinda/smbl\n\n\nRequirements\n------------\n\nTo be able to download and install software automatically, SMBL requires the following programs to be present in you Unix system:\n\n* wget or curl\n* gcc 4.7+\n* git\n* make\n\n\nUsage\n-----\n\nTo use SMBL, you have to import the *smbl*  Python package and include a file with all rules using:\n\n.. code-block:: python\n\n\timport smbl\n\tinclude: smbl.include()\n\n\nThen you can use all supported programs or data. When they appear as input of a rule, they will be downloaded or compiled.\n\nAll the programs are installed into ``~/.smbl/bin/`` and all FASTA files into ``~/.smbl/fa/``.\n\n\nPrograms\n^^^^^^^^\n\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| Program                | Variable with its filename              | Link                                                                    |\n+========================+=========================================+=========================================================================+\n| art\\_454               | ``smbl.prog.ART_454``                   | http://www.niehs.nih.gov/research/resources/software/biostatistics/art/ |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| art\\_illumina          | ``smbl.prog.ART_ILLUMINA``              | http://www.niehs.nih.gov/research/resources/software/biostatistics/art/ |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| art\\_solid             | ``smbl.prog.ART_SOLID``                 | http://www.niehs.nih.gov/research/resources/software/biostatistics/art/ |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| bcftools               | ``smbl.prog.BCFTOOLS``                  | http://github.com/samtools/bcftools                                     |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| bfast                  | ``smbl.prog.BFAST``                     | http://github.com/nh13/bfast                                            |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| bgzip                  | ``smbl.prog.BGZIP``                     | http://github.com/samtools/htslib                                       |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| bowtie2                | ``smbl.prog.BOWTIE2``                   | http://github.com/BenLangmead/bowtie2                                   |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| bowtie2-build          | ``smbl.prog.BOWTIE2_BUILD``             | http://github.com/BenLangmead/bowtie2                                   |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| bowtie2-inspect        | ``smbl.prog.BOWTIE2_INSPECT``           | http://github.com/BenLangmead/bowtie2                                   |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| bwa                    | ``smbl.prog.BWA``                       | http://github.com/lh3/bwa                                               |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| curesim.jar            | ``smbl.prog.CURESIM``                   | http://www.pegase-biosciences.com/tools/curesim/                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| curesim_eval.jar       | ``smbl.prog.CURESIM_EVAL``              | http://www.pegase-biosciences.com/tools/curesim/                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| deez                   | ``smbl.prog.DEEZ``                      | http://github.com/sfu-compbio/deez                                      |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| drfast                 | ``smbl.prog.DRFAST``                    | http://github.com/BilkentCompGen/drfast                                 |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| dwgsim                 | ``smbl.prog.DWGSIM``                    | http://github.com/nh13/dwgsim                                           |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| dwgsim\\_eval.pl        | ``smbl.prog.DWGSIM_EVAL``               | http://github.com/nh13/dwgsim                                           |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| freec                  | ``smbl.prog.FREEC``                     | http://bioinfo-out.curie.fr/projects/freec/                             |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| gem-indexer            | ``smbl.prog.GEM_INDEXER``               | http://algorithms.cnag.cat/wiki/The_GEM_library                         |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| gem-mapper             | ``smbl.prog.GEM_MAPPER``                | http://algorithms.cnag.cat/wiki/The_GEM_library                         |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| gem-2-sam              | ``smbl.prog.GEM_2_SAM``                 | http://algorithms.cnag.cat/wiki/The_GEM_library                         |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| gnuplot4               | ``smbl.prog.GNUPLOT4``                  | http://www.gnuplot.info/                                                |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| gnuplot5               | ``smbl.prog.GNUPLOT5``                  | http://www.gnuplot.info/                                                |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| kallisto               | ``smbl.prog.KALLISTO``                  | https://github.com/pachterlab/kallisto                                  |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| lastal                 | ``smbl.prog.LASTAL``                    | http://last.cbrc.jp/                                                    |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| lastdb                 | ``smbl.prog.LASTDB``                    | http://last.cbrc.jp/                                                    |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mason_frag_sequencing  | ``smbl.prog.MASON_FRAG_SEQUENCING``     | http://packages.seqan.de/mason2/                                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mason_genome           | ``smbl.prog.MASON_GENOME``              | http://packages.seqan.de/mason2/                                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mason_materializer     | ``smbl.prog.MASON_MATERIALIZER``        | http://packages.seqan.de/mason2/                                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mason_methylation      | ``smbl.prog.MASON_METHYLATION``         | http://packages.seqan.de/mason2/                                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mason_simulator        | ``smbl.prog.MASON_SIMULATOR``           | http://packages.seqan.de/mason2/                                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mason_splicing         | ``smbl.prog.MASON_SPLICING``            | http://packages.seqan.de/mason2/                                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mason_variator         | ``smbl.prog.MASON_VARIATOR``            | http://packages.seqan.de/mason2/                                        |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mrfast                 | ``smbl.prog.MRFAST``                    | http://github.com/BilkentCompGen/mrfast                                 |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| mrsfast                | ``smbl.prog.MRSFAST``                   | http://mrsfast.sourceforge.net/                                         |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| perm                   | ``smbl.prog.PERM``                      | http://code.google.com/p/perm/                                          |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| pbsim                  | ``smbl.prog.PBSIM``                     | https://code.google.com/p/pbsim                                         |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| picard                 | ``smbl.prog.PICARD``                    | http://broadinstitute.github.io/picard/                                 |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| sambamba               | ``smbl.prog.SAMBAMBA``                  | http://lomereiter.github.io/sambamba/                                   |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| samtools               | ``smbl.prog.SAMTOOLS``                  | http://github.com/samtools/samtools                                     |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| sirfast                | ``smbl.prog.SIRFAST``                   | http://github.com/BilkentCompGen/sirfast                                |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| storm-color            | ``smbl.prog.STORM_COLOR``               | http://bioinfo.lifl.fr/yass/iedera_solid/storm/                         |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| storm-nucleotide       | ``smbl.prog.STORM_NUCLEOTIDE``          | http://bioinfo.lifl.fr/yass/iedera_solid/storm/                         |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| tabix                  | ``smbl.prog.TABIX``                     | http://github.com/samtools/htslib                                       |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| twoBitToFa             | ``smbl.prog.TWOBITTOFA``                | http://hgdownload.cse.ucsc.edu/admin/exe/                               |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| vcfutils.pl            | ``smbl.prog.VCFTULS``                   | http://github.com/samtools/bcftools                                     |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| wgsim                  | ``smbl.prog.WGSIM``                     | http://github.com/lh3/wgsim                                             |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| wgsim\\_eval.pl         | ``smbl.prog.WGSIM_EVAL``                | http://github.com/lh3/wgsim                                             |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n| xs                     | ``smbl.prog.XS``                        | http://bioinformatics.ua.pt/software/xs/                                |\n+------------------------+-----------------------------------------+-------------------------------------------------------------------------+\n\n\nFASTA files\n^^^^^^^^^^^\n\n+------------------------------+------------------------------------------------------------+\n| FASTA file                   | Variable with its filename                                 |\n+==============================+============================================================+\n| An example small FASTA file  | ``smbl.fasta.EXAMPLE_1``                                   |\n+------------------------------+------------------------------------------------------------+\n| An example small FASTA file  | ``smbl.fasta.EXAMPLE_2``                                   |\n+------------------------------+------------------------------------------------------------+\n| An example small FASTA file  | ``smbl.fasta.EXAMPLE_3``                                   |\n+------------------------------+------------------------------------------------------------+\n| Human genome HG38 (GRCh38)   | ``smbl.fasta.HG38``, ``smbl.fasta.HUMAN_GRCH38``           |\n+------------------------------+------------------------------------------------------------+\n| Mouse genome MM10            | ``smbl.fasta.MOUSE_MM10``                                  |\n+------------------------------+------------------------------------------------------------+\n| Chimpanzee genome PANTR04    | ``smbl.fasta.CHIMP_PANTRO4``                               |\n+------------------------------+------------------------------------------------------------+\n\n\nExample\n-------\n\nThe following example demonstrates how SMBL can be used for automatic installation of software.\n\nCreate an empty file named ``Snakefile`` with the following content:\n\n.. code-block:: python\n\n\timport smbl\n\tinclude: smbl.include()\n\n\trule all:\n\t\tinput:\n\t\t\tsmbl.prog.DWGSIM,\n\t\t\tsmbl.prog.BWA,\n\t\t\tsmbl.fasta.EXAMPLE\n\t\tparams:\n\t\t\tPREF=\"simulated_reads\",\n\t\t\tINDEX=\"bwa_index\"\n\t\toutput:\n\t\t\t\"alignment.sam\"\n\t\trun:\n\t\t\t# read simulation\n\t\t\tshell(\"{input[0]} -C 1 {input[2]} {params.PREF}\")\n\n\t\t\t# creating BWA index of the reference sequence\n\t\t\tshell(\"{input[1]} index {input[2]}\")\n\n\t\t\t# mapping by BWA\n\t\t\tshell(\"{input[1]} mem {input[2]} {params.PREF}.bfast.fastq > alignment.sam\")\n\n\nRun the script.\n\n.. code-block:: bash\n\n\tsnakemake\n\n\nWhat happens:\n\n1. An example FASTA file is downloaded\n2. DwgSim and BWA are downloaded, compiled and installed\n3. DwgSim simulates reads from the example Fasta file\n4. These reads are mapped back to the reference by BWA (*alignment.sam* is created)\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 92,
        "query": "\u26a0\u26a0\u26a0 WARNING WARNING WARNING \u26a0\u26a0\u26a0\n--------------------------------\nThis library is not under active development.\nAfter spending 3 months trying to get support from Box, I finally gave up.\n\nIf anyone is interested in taking over development, please contact me [on Twitter](https://twitter.com/eiopa).\n\n\n\nbox.py - Python client for Box\n------------------------------\n\n[![Build Status](https://secure.travis-ci.org/sookasa/box.py.png?branch=master)](http://travis-ci.org/sookasa/box.py) [![Coverage Status](https://coveralls.io/repos/sookasa/box.py/badge.png)](https://coveralls.io/r/sookasa/box.py)\n\n\nUsage example:\n```python\nfrom box import BoxClient\nfrom StringIO import StringIO\n\nclient = BoxClient('user_token')\nclient.upload_file('hello.txt', StringIO('hello world'))\n```\n\n\nSupported features\n----------------------------\n- File download, upload and overwrite.\n- Delete (including permanent delete), copy, move & restore\n- Directory enumeration\n- Link share\n- User info fetch\n- Thumbnails\n- Search\n- Events + longpoll\n- Collaborations\n\nSupport\n-------\n- Python 2.6+\n- PyPy (dependent on lxml at this point for the v1 authentication flow; see https://bitbucket.org/pypy/compatibility/wiki/lxml)\n\nInstallation\n-------------\n```\n$ pip install box.py\n```\n\nUsage\n=====\n\nUploading a file\n----------------\n```python\nmetadata = client.upload_file('hello.txt', StringIO('hello world'))\n>>> metadata['id']\n'123456'\n```\n\nDownloading a file\n------------------\n```python\nresponse = client.download_file('123456')\n>>> response.text\n'hello world'\n```\n\nDeleting a file\n---------------\n```python\nclient.delete_file('123456')\n```\n\n\nCopying a file\n--------------\n```python\nmetadata = client.copy_file('123456', new_filename='goodbye.txt')\n>>> metadata['id']\n'654321'\n```\n\n\nCopying a folder\n--------------\n```python\nmetadata = client.copy_folder('361015', destination_parent='510163', new_foldername='goodbye')\n>>> metadata['id']\n'149148'\n```\n\n\nReceiving & waiting for events\n------------------------------\n```python\nposition = client.long_poll_for_events() # this will block until there are new events\nevents = client.get_events(position)\n```\n\nAuthenticating a user\n--------------------------\n```python\nfrom box import start_authenticate_v2, finish_authenticate_v2\nurl = start_authenticate_v2('my_api_key')\n>>> url\n'https://www.box.com/api/oauth2/authorize?response_type=code&client_id=my_api_key'\n```\n\nNext, redirect the user to url.\nOnce he accepts, a redirect will be issued to the page defined in your developer settings. The \"code\" is passed as a GET argument.\n\n```python\nhttp_get_params = ... # for django, this would be request.GET\nresponse = finish_authenticate_v2('my_client_id', 'my_client_secret', http_get_params['code'])\n>>> response\n{ 'access_token': '1111111111111111',\n  'restricted_to': [],\n  'token_type': 'bearer',\n  'expires_in': 4056,\n  'refresh_token': '999998988888877766665555444433332221111'\n}\n\n\nclient = BoxClient(response['access_token'])\n```\n\n### Token refresh\nThe v2 security API introduces a mandatory token refresh mechanism (according to Box, this was done to mitigate the impact of token theft).\nEssentially, every so often, the token needs to be \"refreshed\", which involves hitting a Box endpoint with a special \"refresh token\", which returns new access  & refresh tokens that replace the old ones.\nFor more details, see here: http://developers.box.com/oauth/\n\n\nThe refresh dance can be performed explicitly as following:\n```python\nfrom box import refresh_v2_token\nresponse = refresh_v2_token('my_client_id', 'my_client_secret', 'my_refresh_token')\n>>> response\n{ 'access_token': '2222222222222222',\n  'restricted_to': [],\n  'token_type': 'bearer',\n  'expires_in': 4056,\n  'refresh_token': '7777777777777777'\n}\n```\n\nThis can also be done automatically by the client, and you can register a callback that will notify you about the new tokens:\n```python\ndef token_refreshed_callback(access_token, refresh_token):\n\t\"\"\"\n\tthis gets called whenever the tokens have been refreshed. Should persist those somewhere.\n\t\"\"\"\n\tprint 'new access token: ' + access_token\n\tprint 'new refresh token: ' + refresh_token\n\n\nfrom box import CredentialsV2\ncredentials = CredentialsV2('my_access_token', 'my_refresh_token', 'my_client_id', 'my_client_secret', refresh_callback=token_refreshed_callback)\nclient = BoxClient(credentials)\n\nclient.download_file(....) # if the tokens have expired, they will be refreshed automatically and token_refreshed_callback would get invoked\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 93,
        "query": "# jsonasobj\n[![Latest Version](https://img.shields.io/pypi/pyversions/jsonasobj.svg)](https://pypi.python.org/pypi/jsonasobj)\n[![Pyversions](https://img.shields.io/pypi/v/jsonasobj.svg)](https://pypi.python.org/pypi/jsonasobj) \n[![License](https://pypip.in/license/jsonasobj/badge.svg)](https://pypi.python.org/pypi/jsonasobj/)\n![](https://github.com/hsolbrig/jsonasobj/workflows/Build/badge.svg)\n\n## Deprecated\nThere were a number of breaking, albeit highly useful changes in the 2.0.x branch.  Unfortunately, poor requirements\nhygiene on my part made it virtually impossible to gracefully migrate to this new branch.  (Note to self: when using\nSemVer, 'jsonasobj = \">=1.3.1\"` allows version 2.0.0 in w/o complaint.  \"~1.3\" is equivalent to \">= 1.3, == 1.*\".  See\nhttps://www.python.org/dev/peps/pep-0440/#compatible-release for details.).\n\nFuture development will occur on https://github.com/hsolbrig/jsonasobj2.\n\n## Revision History\n* 1.1.0 -- Method signatures all have full typing, `load` function will take a file name, a url -or- an open file as an argument \n* 1.2.0 -- added non-protected access methods and changed copyright\n* 1.2.1 -- fixed issue #4\n* 1.3.0 -- added user filtr to as_json and _as_json_dumps functions, fixed issue #5\n* 1.3.1 -- adjusted filtr so objects \n\n**See:** [Jupyter notebook](notebooks/readme.ipynb) for documentation\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 94,
        "query": "# Python iGlo\n\n## Unmaintained\nThe iGlo range of lights are based on ESP8266 chips and are\ntherefore compatible with a vast number of open source firmwares. \nAs you can't retrieve the state from the stock firmware I advise you\nflash an alternative.\n \n \n----------\n\n\n\nA library to control iGlo based RGB lights.\n\nI am not sure if getting the current state from the light is supported,\nso it is not in this library.\n\n## Example usage\n\n```python\n>>> from iglo import Lamp\n>>> lamp = Lamp('LAMP_ID','LAMP_IP_ADDRESS', 'LAMP_PORT')\n\n>>> lamp.rgb(255,255,0)\n>>> lamp.brightness(100)\n>>> lamp.white(255)\n>>> lamp.switch(False)\n```\n\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 95,
        "query": "Option Merge Addons\n===================\n\nThis is a project that adds an addon system to option_merge enabled projects.\n\nDeprecated\n----------\n\nThis project has been deprecated in favour of https://github.com/delfick/delfick_project\n\nInstallation\n------------\n\nUse pip!:\n\n.. code-block:: bash\n\n    pip install option_merge_addons\n\nOr if you're developing it:\n\n.. code-block:: bash\n\n    pip install -e .\n    pip install -e \".[tests]\"\n\nTests\n-----\n\nRun the helpful script:\n\n.. code-block:: bash\n\n    ./test.sh\n\nUsage\n-----\n\nThere are two parts to using this module: the setup, and the addons.\n\nSetup\n+++++\n\n.. code-block:: python\n\n    from option_merge_addons import Result, Addon, Register, AddonGetter\n\n    # collector is passed into the hooks. It may be None\n    # It's expected to be http://option-merge.readthedocs.io/en/latest/docs/api/collector.html\n    collector = None\n\n    # Create the addon getter and register our namespace\n    addon_getter = AddonGetter()\n    addon_getter.add_namespace(\"my_amazing_addons\", Result.FieldSpec(), Addon.FieldSpec())\n\n    # Initiate the addons from our configuration\n    register = Register(addon_getter, collector)\n\n    # Register and execute our addons\n    # This will import the ns1.name1 addon, which will bring in it's dependencies\n    # and so on\n    # And then run the post_register hooks with {\"arg\": 1, \"arg2\": 2} as kwargs\n    start_addons = [(\"ns1\", \"name1\")]\n    register.register(*start_addons, my_amazing_addons={\"arg1\": 1, \"arg2\": 2})\n\nNote that you can split up that last line into different stages you run at\ndifferent times with whatever you want before. This is helpful if you want to\ndo something before calling the post_register hooks:\n\n.. code-block:: python\n\n    # Add atleast one entry point that will start importing other entry points\n    default_addons = [(\"ns1\", \"name1\"), (\"ns2\", \"name2\")]\n    register.add_pairs(*default_addons)\n\n    # Import our addons\n    register.recursive_import_known()\n\n    # Resolve our addons\n    register.recursive_resolve_imported()\n\n    # extra_args specifies what goes into the post_register hooks\n    extra_args = {\"my_amazing_addons\": {\"arg1\": 1}}\n    self.register.post_register(extra_args)\n\nYou can also define your own entry points programmatically by doing something\nlike:\n\n.. code-block:: python\n\n    # Register __main__ as an entry point\n    try:\n        __main__ = __import__(\"__main__\")\n    except ImportError:\n        pass\n    else:\n        if any(hasattr(getattr(__main__, attr, None), \"_option_merge_addon_entry\") for attr in dir(__main__)):\n            working_set = pkg_resources.working_set\n            dist = pkg_resources.Distribution(\"__main__\")\n            mp = pkg_resources.EntryPoint.parse_group(\"my_amazing_addons\", [\"__main__ = __main__\"])\n\n            def get_entry_map(group=None):\n                if group == \"my_amazing_addons\":\n                    return mp\n                return {}\n            dist.get_entry_map = get_entry_map\n            working_set.add(dist, entry=\"__main__\")\n\nDefining hooks\n++++++++++++++\n\nThere are two parts to defining a hook. The first part is to define it:\n\n.. code-block:: python\n\n    from option_merge_addons import option_merge_addon_hook\n\n    @option_merge_addon_hook(extras=[('my_amazing_addons', 'thing1'), ('my_amazing_addons', 'thing2')])\n    def __addon__(collector, results_maker, **kwargs):\n        # Setup things here\n        # We can return None or we can use results_maker to programmatically\n        # add more dependencies\n        return results_maker(extras=[(\"my_amazing_addons\", \"thing3\")])\n\n    @option_merge_addon_hook(post_register=True)\n    def __addon_post__(collector, **kwargs):\n        # Setup that must be done after all dependencies have been resolved\n        # And imported and had their first hook executed\n\nThe second part is to define the entry points in your setup.py. So if the above\nhooks was at ``my_amazing_module.addons`` then your setup.py would look like:\n\n.. code-block:: python\n\n    from setuptools import setup\n\n    setup(\n          ...\n\n          , entry_points =\n          { \"my_amazing_addons\": [\"amazing = my_amazing_module.addon\"]\n          }\n        )\n\nOnce this package is installed in your environment, you may depend on it by\nspecifying ``(\"my_amazing_addons\", \"amazing\")``.\n\nImport Order\n++++++++++++\n\nThe several passes of importing modules goes as follows:\n\n1. Import all our known hooks\n2. Keep importing all the dependencies that we find\n3. Once we've imported everything, start calling the hooks and add any depdencies\n   returned by the hooks to our known addons.\n4. Go to step 1 unless we've imported and resolved everything\n\nThe order is such that all dependencies are resolved before a hook that asked\nfor dependencies is resolved.\n\nThe post_register also follows this where all dependencies are resolved before\na hook that asks for them.\n\nAsking for all hooks in a namespace\n+++++++++++++++++++++++++++++++++++\n\nYou may specify a special ``(\"namespace\", \"__all__\")``  dependency which will\nmake that hook depend on all hooks that haven't already been imported. Note that\nthis should be used sparingly as a hook that asks for it cannot be explicitly\nasked for by another hook.\n\nChangelog\n---------\n\n0.3\n    Made it possible to specify ``(\"namespace\", \"__all__\")`` from a hook\n\n0.2.1\n    No changelog was kept before now\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 96,
        "query": "Transifex Command-Line Tool\n===========================\n[![image](https://circleci.com/gh/transifex/transifex-client/tree/master.svg?style=shield&circle-token=33aafd984726261eff1b73278a0cf761382c478a)](https://circleci.com/gh/transifex/transifex-client/tree/master)\n[![image](https://ci.appveyor.com/api/projects/status/github/transifex/transifex-client?branch=master&svg=true)](https://ci.appveyor.com/project/transifex/transifex-client/branch/master)\n[![codecov](https://codecov.io/gh/transifex/transifex-client/branch/master/graph/badge.svg)](https://codecov.io/gh/transifex/transifex-client)\n[![PyPI version](https://badge.fury.io/py/transifex-client.svg)](https://badge.fury.io/py/transifex-client)\n\n## The New Client \ud83c\udf89\nWe released a stable version of a new Transifex Client, compatible with the [new API](https://transifex.github.io/openapi/), and offered as single executable.\n\nPlease start using the new Transifex CLI [here](https://github.com/transifex/cli) , since this software is considered deprecated (as of January 2022) and will sunset on Nov 30, 2022.\n\n## Getting started\nWhether you have experience with the command line or not, [this interactive tutorial](https://www.transifex.com/learn/txclient/) is intended for everyone who wishes to learn how the Transifex client works. There is no need to download anything - Just click on the link provided above, and follow the instructions.\n\nFor more information about TX client, please visit our [documentation guide here](https://docs.transifex.com/client/introduction).\n\nDescription\n---\nThe Transifex Command-line Tool enables you to manage your translations within a project without the need of an elaborate UI system.\n\nYou can use the command line tool to create new resources, map locale files to translations, and synchronize your Transifex project with your local repository. Translators and localization managers can use it to handle large volumes of translation files.  The Transifex Command-line Tool can help to enable continuous integration workflows and can be run from CI servers like Jenkins and Bamboo.\n\n[Click  here](http://docs.transifex.com/client/) for complete documentation on the Transifex Command-line Tool via our documentation site.\n\nInstallation\n------------\n\nYou can install the latest version of transifex-client running `pip install transifex-client` or `easy_install transifex-client`.\n\nBuild transifex-client for Windows\n----------------------------------\n\n1.  Download transifex-client sources via git or github archive.\n    1.  `git clone https://github.com/transifex/transifex-client.git`\n    2.  Download and unpack <https://github.com/transifex/transifex-client/archive/master.zip>\n\n2.  Download and install [Python](https://www.python.org/downloads/windows/).\n\n    At this step choose the right version of python (2.7, 3.5, 3.6 or 3.7) and x86 or x86-64 instruction set.\n\n    Make sure pip marked for installation(default for latest installers).\n\n3.  Install [PyInstaller](http://www.pyinstaller.org).\n\n    Suppose that Python installed to `C:\\\\Program Files\\\\Python35-32`\n\n    Make `python.exe` accessible via PATH environment variable or cd to directory containing python.exe.\n\n        python -m pip install pyinstaller\n\n    This command will install `PyInstaller` package and its dependencies.\n\n4.  Build `transifex-client` distribution.\n\n    Change directory to transifex-client folder and run command:\n\n        python -m PyInstaller contrib/tx.spec\n        # or\n        pyinstaller contrib/tx.spec\n\n5.  `tx.exe`\n\n    `dist/tx.exe` will be created as the result of build process.\n\n\nGetting Help\n---\nYou can always get additional help via [GitHub issues](https://github.com/transifex/transifex-client/issues) or [Transifex support](https://www.transifex.com/contact/)\n\nLicense\n---\nTransifex Client is primarily distributed under the terms of the GPL License (Version 2.0).\n\nSee [LICENSE](https://github.com/transifex/transifex-client/blob/master/LICENSE) for details.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 97,
        "query": "# rcghci - A remote control for GHCI\n\n# Deprecated in favor of https://github.com/sras/repltalk\n\nThis is a python3 script that straps on something like a RPC interface to a GHCI process.\n\nYou can install it using `pip`\n\n```\npip3 install rcghci\n```\n\nTo start it, open a terminal and set the following environment variables.\n\n```\nexport RCGHCI_ERROR_FILE=/home/<username>/errors.txt\nexport RCGHCI_PROMPT='RCGHCIPROMPT>>>'\n```\n\nNow change directory to your project, and instead of running `stack ghci`\nrun `rcghci` followed by what ever options that you have to pass to the `stack ghci` command.\n\nYou will see the `stack ghci` command starting up, and if you have the `tkinter` library installed\na gui will open up.\n\nYou can install the tkinter library using the following command\n\n```\nsudo apt-get install python3-tk\n```\n\n### Configuring neovim\n\nAdd the following lines to you neovim configuration.\n\n```\nlet g:rcghci_ip = \"127.0.0.1\"\nlet g:rcghci_port = \"1880\"\nlet g:error_path = \"~\"\n\nfunction! Ghci(command)\n  silent exec \"!echo \". a:command . \"> /dev/tcp/\" . g:rcghci_ip . \"/\" . g:rcghci_port\nendfunction\n\nfunction! GHCIBridgeSetErrors()\n  hi StatusLine ctermfg=black guibg=black ctermbg=red guifg=#fc4242\nendfunction\n\nfunction! GHCIBridgeSetWarnings()\n  hi StatusLine ctermfg=black guibg=black ctermbg=yellow guifg=#84ff56\nendfunction\n\nfunction! GHCIBridgeSetSuccess()\n  hi StatusLine ctermfg=black guibg=black ctermbg=green guifg=#087e3b\nendfunction\n\nfunction! GHCIBridgeSetActivity()\n  hi StatusLine ctermfg=black guibg=black ctermbg=brown guifg=orange\nendfunction\n\nfunction! LiveCompile()\n  call Ghci(\":reload\")\nendfunction\n\nfunction! OpenErrors()\n  execute \":cclose\"\n  execute \":cfile \" . g:error_path .\"/errors.txt\"\n  execute \":cope\"\nendfunction\n\nfunction! CloseErrors()\n  cclose\nendfunction\n\ncommand! HSendConfig call Ghci(\"socket=\".$NVIM_LISTEN_ADDRESS)\n\nautocmd BufWritePost *.hs call LiveCompile()\n```\n\nAfter you start the nvim editor, just call the `HSendConfig` command, which sends the neovim rpc socket\nto the RCGHCI script.\n\nopen a Haskell source file in your project (The same one you have started the rcghci script in) to start using the script.\n\n# Live Reload\n\nThe neovim configuration we have added will send a reload command to the script when a Haskell file is saved. This causes\nthe wrapped rcghci script to do a \":reload\" command, and ends up reloading all the changed files. The output of the ghci\nprocess is parsed by the script into errors and warnings. These are then written to an error file, who's path we have configured\nusing the `RCGHCI_ERROR_FILE` environment variable. We have also set the path of the vim error file to be the same. This means\nyou can use vim's native error file navigation capabilities to navigate the error locations, including the ability to open them\nin the editor simply by pressing `enter` when the cursor is on the path in the vim's error list display.\n\nWhen you have triggerred a reload by saving a Haskell source file, the script will change the color of the status bar to indicate\nthat a command is in progress. It will switch the status bar color after the command has finished execution. If there are any errors\nit will be a different color. You can configure the colors by changing them in the `GHCIBridgeSetErrors()`, `GHCIBridgeSetWarnings()`\nfunctions.\n\n# Using the GUI\n\nYou can also open an error location in neovim by clicking on the error that is displayed in the gui.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 98,
        "query": "flask-saml2\n===========\n\n.. note::\n    **Looking for maintainers**. This project is unmaintained. The library works, or did when I last used it,\n    but I no longer work on the project this was built for. If you are interested in taking over leadership\n    and maintenance of this project, please get in touch.\n\n.. image:: https://travis-ci.com/timheap/flask-saml2.svg?branch=master\n    :target: https://travis-ci.com/timheap/flask-saml2\n.. image:: https://badge.fury.io/py/flask-saml2.svg\n    :target: https://pypi.org/project/flask-saml2/\n.. image:: https://readthedocs.org/projects/flask-saml2/badge/?version=latest\n    :target: https://flask-saml2.readthedocs.io/en/latest/\n\nThis Flask plugin provides functionality for creating both SAML Service\nProviders and Identity Providers. Applications can implement one or both of\nthese providers.\n\n``flask-saml2`` works with Flask 1.0+ and Python 3.6+.\n\nThis is a heavily modified fork of `NoodleMarkets/dj-saml-idp`_ which in turn\nis a fork of `deforestg/dj-saml-idp`_ which in turn is a fork of\n`novapost/django-saml2-idp`_.\n\nTerminology\n-----------\n\nFor a full description of how SAML works, please seek guides elsewhere on the\ninternet. For a quick introduction, and a run through of some of the\nterminology used in this package, read on.\n\nThe SAML protocal is a conversation between two parties:\n**Identity Providers (IdP)** and **Service Providers (SP)**.\nWhen an unauthenticated client (usually a browser) accesses a Service Provider,\nthe Service Provider will make an **authentication request (AuthnRequest)**,\nsign it using its private key, and then forward this request via the client to\nthe Identity Provider. Once the client logs in at the central Identity\nProvider, the Identity Provider makes a response, signs it, and forwards this\nresponse via the client to the requesting Service Provider. The client is then\nauthenticated on the Service Provider via the central Identity Provider,\nwithout the Service Provider having to know anything about the authentication\nmethod, or any passwords involved.\n\nExample implementations\n-----------------------\n\nA minimal but functional example implementation of both a Service Provider and\nan Identity Provider can be found in the ``examples/`` directory of this\nrepository. To get the examples running, first clone the repository and install\nthe dependencies:\n\n.. code-block:: console\n\n    $ git clone https://github.com/timheap/flask-saml2\n    $ cd flask-saml2\n    $ python3 -m venv venv\n    $ source venv/bin/activate\n    $ pip install -e .\n    $ pip install -r tests/requirements.txt\n\nNext, run the IdP and the SP in separate terminal windows:\n\n.. code-block:: console\n\n    $ cd flask-saml2\n    $ source venv/bin/activate\n    $ ./examples/idp.py\n\n.. code-block:: console\n\n    $ cd flask-saml2\n    $ source venv/bin/activate\n    $ ./examples/sp.py\n\nFinally, navigate to http://localhost:9000/ to access the Service Provider\nlanding page.\n\nTesting\n-------\n\nThe test runner is `pytest` and we are using `tox` to run tests against\ndifferent versions of Flask and Python. The test can be run locally using\n`tox` directly (preferably in a virtual environment)::\n\n    $ pip install tox\n    $ tox\n\nLicense\n-------\n\nDistributed under the `MIT License`_.\n\n.. _`NoodleMarkets/dj-saml-idp`: https://github.com/NoodleMarkets/dj-saml-idp\n.. _`deforestg/dj-saml-idp`: https://github.com/deforestg/dj-saml-idp\n.. _`novapost/django-saml2-idp`: https://github.com/novapost/django-saml2-idp\n.. _`MIT License`: https://github.com/mobify/dj-saml-idp/blob/master/LICENSE\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    },
    {
        "id": 99,
        "query": "# DEPRECATED. See https://github.com/endrebak/SICER2\n\nI would recommend you rerun your analyses with epic2 as it uses the exact same recurrence relation computation as SICER, without any heuristics. This is a very minor issue though :)\n\n# epic: diffuse domain ChIP-Seq caller based on SICER\n\n[![Build Status](https://travis-ci.org/biocore-ntnu/epic.svg?branch=master)](https://travis-ci.org/biocore-ntnu/epic) [![Coverage Status](https://coveralls.io/repos/github/biocore-ntnu/epic/badge.svg?branch=master)](https://coveralls.io/github/biocore-ntnu/epic?branch=master) [![Code Health](https://landscape.io/github/biocore-ntnu/epic/master/landscape.svg?style=flat)](https://landscape.io/github/biocore-ntnu/epic/master) [![install with bioconda](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg?style=flat-square)](http://bioconda.github.io/recipes/epic/README.html) [![Documentation Status](https://readthedocs.org/projects/bioepic/badge/?version=latest)](http://bioepic.readthedocs.org/en/latest/)\n\nepic is a software package for finding medium to diffusely enriched domains in\nchip-seq data. It is a fast, parallel and memory-efficient implementation of the\nincredibly popular SICER algorithm. By running epic on a set of data (\"ChIP\")\nfiles and control (\"Input\") files, epic is able to quickly\ndifferentially enriched regions.\n\nepic is an improvement over the original SICER by being faster, more memory\nefficient, multicore, and significantly much easier to install and use.\n\nThe MIT-licensed code is available at https://github.com/endrebak/epic\n\nThe [documentation](http://bioepic.readthedocs.io/en/latest/) is currently being worked on.\n\n<!-- If you use, or intend to use epic, please say hi in this google -->\n<!-- groups -->\n<!-- [thread](https://groups.google.com/forum/#!topic/epic-chip-seq/zWlsun_yfZQ). -->\n<!-- This would help me better understand how many people actually use it - it seems -->\n<!-- like the bugreports, stars and feature requests I get is only a teensy tip of the ice -->\n<!-- berg. -->\n\n<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-generate-toc again -->\n**Table of Contents**\n- [epic: diffuse domain ChIP-Seq caller based on SICER](#epic-diffuse-domain-chip-seq-caller-based-on-sicer)\n    - [Install](#install)\n    - [Changelog](#changelog)\n    - [Improvements](#improvements)\n    - [Version](#version)\n    - [License](#license)\n    - [Requirements](#requirements)\n    - [Helper scripts](#helper-scripts)\n    - [Usage](#usage)\n    - [Credit](#credit)\n    - [NAQ/Various](#naqvarious)\n\n\n<!-- markdown-toc end -->\n## Citation\n\nFor now, please cite the original SICER paper, but include a link to this repo.\n\n## Install\n\nepic is available for python2.7 and above. It can be installed from the Python\nPackage Index with `pip install bioepic` or preferably from bioconda with `conda\ninstall -c bioconda epic`, or by cloning the repo at\nhttps://github.com/endrebak/epic and running `python setup.py install`\n<!-- , with bioconda using `conda install bioepic` ([bioconda setup instructions](http://bioconda.github.io/index.html#setup)) -->\n\n## Changelog\n\n```\n# 0.2.12 (02.08.18)\n- Fix bug in bigwig creation (due to new pd behavior)\n\n# 0.2.11 (01.08.18)\n- Massive speedup with Cython\n- Fix bugs added by 0.2.10\n\n# 0.2.10 (31.07.18)\n- Use categoricals for memory efficiency and speed\n- Fix bug in epic when using chromsizes\n```\n\n## Quickstart\n\n```\n$ pip install bioepic\n$ # you only need git clone to get the test data\n$ git clone https://github.com/endrebak/epic.git\n$ # -t is treatment files, -c input (control) files\n$ epic -t epic/examples/test.bed -c epic/examples/control.bed > results.csv\n```\n\n## Improvements\n\n#### Actively developed\n\nWill be maintained and further updated.\n\nWe hope to make further refinements to the actual algorithm and make it even better.\n\n#### Functionality\n\nepic accepts several input and ChIP files at the same time and accepts bed files\n- both block-zipped and gzipped.\n\nWorks on files of any size.\n\nWorks on all Python versions 2.7/3+.\n\n#### Speed\n\nepic can use one core per chromosome, which should give a speedup of < ~22-25\n(differs by species) by itself. In addition, epic uses the Python science stack,\nincluding Pandas, for almost all tasks, which means each core runs heavily\noptimized C, Fortran and Cython code for further speed gains.\n\n#### Memory\n\nepic streams the data instead of loading it all into memory, which should result\nin a much smaller memory footprint.\n\n#### Usage\n\nInstead of needing eleven command line arguments to run, epic contains sensible\ndefaults and only needs the files it is to analyze as parameters.\n\nepic can be run from whichever location with files found anywhere on the disk.\n\nContains many [genomes](https://github.com/endrebak/epic/tree/master/epic/scripts/chromsizes), with updated effective genome sizes. If your genome isn't listed, please request it!\n\n## Version\n\nThis is a beta release. Please do aggressively report issues, quirks, complaints and anything that just feels slightly off to the issue tracker. Also please ask questions and make docrequests - there is loads of neat stuff I have not documented.\n\n## License\n\nMIT\n\n## Requirements\n\nPython data science stack and a fairly recent version of Pandas (0.17 >=).\nPython 2.7 or 3+.\nVarious unix tools found on all major distributions.\n\nFor the effective genome size script [jellyfish2](https://github.com/gmarcais/Jellyfish) is required.\n\n## Helper scripts\n\nSee [this page](helper_scripts.md) for the various helper scripts that are a part of epic.\n\n## Converting bam files to bed\n\nIf you have bam files, these can be converted to bed with the command\n\n```\nbamToBed -i file.bam > file.bed\n```\n\nIf you have paired-end data, you can use\n\n```\nbamToBed -bedpe -i paired_end_file.bam > file.bedpe\n```\n\n## Usage\n\n(Might be slightly out of date.)\n\n```\nusage: epic [-h] --treatment TREATMENT [TREATMENT ...] --control CONTROL\n            [CONTROL ...] [--number-cores NUMBER_CORES] [--genome GENOME]\n            [--keep-duplicates] [--window-size WINDOW_SIZE]\n            [--gaps-allowed GAPS_ALLOWED] [--fragment-size FRAGMENT_SIZE]\n            [--false-discovery-rate-cutoff FALSE_DISCOVERY_RATE_CUTOFF]\n            [--effective_genome_fraction EFFECTIVE_GENOME_FRACTION]\n            [--chromsizes CHROMSIZES] [--store-matrix STORE_MATRIX]\n            [--bigwig BIGWIG] [--sum-bigwig SUM_BIGWIG] [--bed BED]\n            [--log LOG] [--outfile OUTFILE] [--version]\n\nDiffuse domain ChIP-Seq caller based on SICER. (Visit github.com/endrebak/epic\nfor examples and help.)\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --treatment TREATMENT [TREATMENT ...], -t TREATMENT [TREATMENT ...]\n                        Treatment (pull-down) file(s) in (b/gzipped) bed/bedpe\n                        format.\n  --control CONTROL [CONTROL ...], -c CONTROL [CONTROL ...]\n                        Control (input) file(s) in (b/gzipped) bed/bedpe\n                        format.\n  --number-cores NUMBER_CORES, -cpu NUMBER_CORES\n                        Number of cpus to use. Can use at most one per\n                        chromosome. Default: 1.\n  --genome GENOME, -gn GENOME\n                        Which genome to analyze. Default: hg19.\n  --keep-duplicates, -k\n                        Keep reads mapping to the same position on the same\n                        strand within a library. Default is to remove all but\n                        the first duplicate.\n  --window-size WINDOW_SIZE, -w WINDOW_SIZE\n                        Size of the windows to scan the genome. WINDOW_SIZE is\n                        the smallest possible island. Default 200.\n  --gaps-allowed GAPS_ALLOWED, -g GAPS_ALLOWED\n                        Multiple of window size used to determine the gap\n                        size. Must be an integer. Default: 3.\n  --fragment-size FRAGMENT_SIZE, -fs FRAGMENT_SIZE\n                        (Single end reads only) Size of the sequenced\n                        fragment. The center of the the fragment will be taken\n                        as half the fragment size. Default 150.\n  --false-discovery-rate-cutoff FALSE_DISCOVERY_RATE_CUTOFF, -fdr FALSE_DISCOVERY_RATE_CUTOFF\n                        Remove all islands with an FDR below cutoff. Default\n                        0.05.\n  --effective_genome_fraction EFFECTIVE_GENOME_FRACTION, -egf EFFECTIVE_GENOME_FRACTION\n                        Use a different effective genome fraction than the one\n                        included in epic. The default value depends on the\n                        genome and readlength, but is a number between 0 and\n                        1.\n  --chromsizes CHROMSIZES, -cs CHROMSIZES\n                        Set the chromosome lengths yourself in a file with two\n                        columns: chromosome names and sizes. Useful to analyze\n                        custom genomes, assemblies or simulated data. Only\n                        chromosomes included in the file will be analyzed.\n  --store-matrix STORE_MATRIX, -sm STORE_MATRIX\n                        Store the matrix of counts per bin for ChIP and input\n                        to gzipped file <STORE_MATRIX>.\n  --bigwig BIGWIG, -bw BIGWIG\n                        For each file, store a bigwig of both enriched and\n                        non-enriched regions to folder <BIGWIG>. Requires\n                        different basenames for each file.\n  --sum-bigwig SUM_BIGWIG, -sbw SUM_BIGWIG\n                        Store two bigwigs - one of ChIP, one of input - to\n                        folder <SUM-BIGWIG>.\n  --bed BED, -b BED     A summary bed file of all regions for display in the\n                        UCSC genome browser or downstream analyses with e.g.\n                        bedtools. The score field is log2(#ChIP/#Input) * 100\n                        capped at a 1000.\n  --log LOG, -l LOG     File to write log messages to.\n  --outfile OUTFILE, -o OUTFILE\n                        File to write results to. By default sent to stdout.\n  --version, -v         show program's version number and exit\n```\n\n## Credit\n\nChongzhi Zang, Dustin E. Schones, Chen Zeng, Kairong Cui, Keji Zhao and Weiqun Peng for the original SICER. Please consider citing their paper (*in addition* to our eventual paper) if you use epic. And if you use any (helper) scripts in SICER that are not included in epic you should of course cite the SICER paper!\n\nMost of the improvements in epic were possible due to Python Science libraries that were not available when SICER was originally written. Thanks to the Pandas developers!\n\n#### Author\n\nEndre Bakken Stovner\n\n#### Contributors\n\n* P\u00e5l S\u00e6trom (algorithmic/theoretical discussions, endless patience)\n* Dario Beraldi (argparsing)\n* Ryan Dale (bioconda, ideas, genome info script)\n* Ryan C. Thompson (bigwig improvements, mypy typing)\n\n#### Thanks\n\n* Piotr Balwierz (helping me debug the paired-end mode)\n* Keith Siklenka (lending me a subset of some paired-end ChIP-Seq files)\n\n#### Performance, differential ChIP-Seq\n\n![alt tag](img/4C.png)\n\nBriefings in Bioinformatics, 2016, 1\u201314\n\n## NAQ/Various\n\nAnswers to some questions no-one has ever asked me.\n\n#### Why is the SICER algorithm so great?\n\nThe wonderful thing about the SICER algorithm is that is very careful about dropping windows with few reads in them. All ChIP-seq callers I know have some preprocessing step where this is done liberally. SICER pools these windows together and gives them a composite score, allowing very long stretches of very diffuse signal to be detected.\n\n#### Why another ChIP-Seq domain caller?\n\nMACS2 is great for narrow peaks, but epic performs better on diffuse domains. For medium size domains, such as PolII, our tests indicate that both perform about equally well, but epic uses only a fraction of the time.\n\n#### Why not SICER?\n\nSICER contains a great algorithm and is a wonderful piece of software, but advances in the Python data science libraries has made it possible to implement it much more efficiently. Furthermore, SICER was not made to handle the mountains of data we have now; it simply cannot run on very large datasets due to (sensible) restrictions in the original implementation.\n\n#### When is your paper coming out?\n\nDunno. We do not want to write a methods paper, but rather just include a section about epic in an appropriate biology paper sometime.\n\n#### Why the name epic?\n\nIt stands for electronic pic [sic] caller or epigenome cartographer, whichever you prefer. Or perhaps it isn't just another bogus bioinformatics acronym. Hope you find the name fitting.\n\nBut suggestions for better names accepted. On paper I liked the epi/epic/epigenetics link but now when I hear it it sounds so boastful I cringe. exorcised sounds like a slight on the original software... Mad MACS?\n\n#### Which other ChIP-Seq callers do you use?\n\n* [SICER](http://home.gwu.edu/~wpeng/Software.htm) - great diffuse domain ChIP-Seq caller (which epic is based on.)\n* [SICERpy](https://github.com/dariober/SICERpy) - a wrapper around SICER for convenience/parallelism. Stole some good ideas from there.\n* [csaw](https://github.com/LTLA/csaw) - R package. Uses an approach to island finding that complements epic very well. Requires more statistical sophistication and programming skill to use.\n* [MACS2](https://github.com/taoliu/MACS) - my preferred peak caller.\n",
        "model_answer": "",
        "alternative_method": "",
        "label": 1
    }
]